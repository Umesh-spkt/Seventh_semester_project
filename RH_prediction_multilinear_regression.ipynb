{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting Relative humidy using 11 features of Air Quality data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "AirQuality = pd.read_csv(\"AirQuality.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>CO(GT)</th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>NMHC(GT)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>NO2(GT)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10/3/2004</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1360</td>\n",
       "      <td>150</td>\n",
       "      <td>11.9</td>\n",
       "      <td>1046</td>\n",
       "      <td>166</td>\n",
       "      <td>1056</td>\n",
       "      <td>113</td>\n",
       "      <td>1692</td>\n",
       "      <td>1268</td>\n",
       "      <td>13.6</td>\n",
       "      <td>48.9</td>\n",
       "      <td>0.7578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10/3/2004</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1292</td>\n",
       "      <td>112</td>\n",
       "      <td>9.4</td>\n",
       "      <td>955</td>\n",
       "      <td>103</td>\n",
       "      <td>1174</td>\n",
       "      <td>92</td>\n",
       "      <td>1559</td>\n",
       "      <td>972</td>\n",
       "      <td>13.3</td>\n",
       "      <td>47.7</td>\n",
       "      <td>0.7255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10/3/2004</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1402</td>\n",
       "      <td>88</td>\n",
       "      <td>9.0</td>\n",
       "      <td>939</td>\n",
       "      <td>131</td>\n",
       "      <td>1140</td>\n",
       "      <td>114</td>\n",
       "      <td>1555</td>\n",
       "      <td>1074</td>\n",
       "      <td>11.9</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.7502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10/3/2004</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1376</td>\n",
       "      <td>80</td>\n",
       "      <td>9.2</td>\n",
       "      <td>948</td>\n",
       "      <td>172</td>\n",
       "      <td>1092</td>\n",
       "      <td>122</td>\n",
       "      <td>1584</td>\n",
       "      <td>1203</td>\n",
       "      <td>11.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.7867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10/3/2004</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1272</td>\n",
       "      <td>51</td>\n",
       "      <td>6.5</td>\n",
       "      <td>836</td>\n",
       "      <td>131</td>\n",
       "      <td>1205</td>\n",
       "      <td>116</td>\n",
       "      <td>1490</td>\n",
       "      <td>1110</td>\n",
       "      <td>11.2</td>\n",
       "      <td>59.6</td>\n",
       "      <td>0.7888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9352</td>\n",
       "      <td>4/4/2005</td>\n",
       "      <td>10:00:00</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1314</td>\n",
       "      <td>-200</td>\n",
       "      <td>13.5</td>\n",
       "      <td>1101</td>\n",
       "      <td>472</td>\n",
       "      <td>539</td>\n",
       "      <td>190</td>\n",
       "      <td>1374</td>\n",
       "      <td>1729</td>\n",
       "      <td>21.9</td>\n",
       "      <td>29.3</td>\n",
       "      <td>0.7568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9353</td>\n",
       "      <td>4/4/2005</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1163</td>\n",
       "      <td>-200</td>\n",
       "      <td>11.4</td>\n",
       "      <td>1027</td>\n",
       "      <td>353</td>\n",
       "      <td>604</td>\n",
       "      <td>179</td>\n",
       "      <td>1264</td>\n",
       "      <td>1269</td>\n",
       "      <td>24.3</td>\n",
       "      <td>23.7</td>\n",
       "      <td>0.7119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9354</td>\n",
       "      <td>4/4/2005</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1142</td>\n",
       "      <td>-200</td>\n",
       "      <td>12.4</td>\n",
       "      <td>1063</td>\n",
       "      <td>293</td>\n",
       "      <td>603</td>\n",
       "      <td>175</td>\n",
       "      <td>1241</td>\n",
       "      <td>1092</td>\n",
       "      <td>26.9</td>\n",
       "      <td>18.3</td>\n",
       "      <td>0.6406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9355</td>\n",
       "      <td>4/4/2005</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1003</td>\n",
       "      <td>-200</td>\n",
       "      <td>9.5</td>\n",
       "      <td>961</td>\n",
       "      <td>235</td>\n",
       "      <td>702</td>\n",
       "      <td>156</td>\n",
       "      <td>1041</td>\n",
       "      <td>770</td>\n",
       "      <td>28.3</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.5139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9356</td>\n",
       "      <td>4/4/2005</td>\n",
       "      <td>14:00:00</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1071</td>\n",
       "      <td>-200</td>\n",
       "      <td>11.9</td>\n",
       "      <td>1047</td>\n",
       "      <td>265</td>\n",
       "      <td>654</td>\n",
       "      <td>168</td>\n",
       "      <td>1129</td>\n",
       "      <td>816</td>\n",
       "      <td>28.5</td>\n",
       "      <td>13.1</td>\n",
       "      <td>0.5028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9357 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date      Time  CO(GT)  PT08.S1(CO)  NMHC(GT)  C6H6(GT)  \\\n",
       "0     10/3/2004  18:00:00     2.6         1360       150      11.9   \n",
       "1     10/3/2004  19:00:00     2.0         1292       112       9.4   \n",
       "2     10/3/2004  20:00:00     2.2         1402        88       9.0   \n",
       "3     10/3/2004  21:00:00     2.2         1376        80       9.2   \n",
       "4     10/3/2004  22:00:00     1.6         1272        51       6.5   \n",
       "...         ...       ...     ...          ...       ...       ...   \n",
       "9352   4/4/2005  10:00:00     3.1         1314      -200      13.5   \n",
       "9353   4/4/2005  11:00:00     2.4         1163      -200      11.4   \n",
       "9354   4/4/2005  12:00:00     2.4         1142      -200      12.4   \n",
       "9355   4/4/2005  13:00:00     2.1         1003      -200       9.5   \n",
       "9356   4/4/2005  14:00:00     2.2         1071      -200      11.9   \n",
       "\n",
       "      PT08.S2(NMHC)  NOx(GT)  PT08.S3(NOx)  NO2(GT)  PT08.S4(NO2)  \\\n",
       "0              1046      166          1056      113          1692   \n",
       "1               955      103          1174       92          1559   \n",
       "2               939      131          1140      114          1555   \n",
       "3               948      172          1092      122          1584   \n",
       "4               836      131          1205      116          1490   \n",
       "...             ...      ...           ...      ...           ...   \n",
       "9352           1101      472           539      190          1374   \n",
       "9353           1027      353           604      179          1264   \n",
       "9354           1063      293           603      175          1241   \n",
       "9355            961      235           702      156          1041   \n",
       "9356           1047      265           654      168          1129   \n",
       "\n",
       "      PT08.S5(O3)     T    RH      AH  \n",
       "0            1268  13.6  48.9  0.7578  \n",
       "1             972  13.3  47.7  0.7255  \n",
       "2            1074  11.9  54.0  0.7502  \n",
       "3            1203  11.0  60.0  0.7867  \n",
       "4            1110  11.2  59.6  0.7888  \n",
       "...           ...   ...   ...     ...  \n",
       "9352         1729  21.9  29.3  0.7568  \n",
       "9353         1269  24.3  23.7  0.7119  \n",
       "9354         1092  26.9  18.3  0.6406  \n",
       "9355          770  28.3  13.5  0.5139  \n",
       "9356          816  28.5  13.1  0.5028  \n",
       "\n",
       "[9357 rows x 15 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AirQuality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Time', 'CO(GT)', 'PT08.S1(CO)', 'NMHC(GT)', 'C6H6(GT)',\n",
       "       'PT08.S2(NMHC)', 'NOx(GT)', 'PT08.S3(NOx)', 'NO2(GT)', 'PT08.S4(NO2)',\n",
       "       'PT08.S5(O3)', 'T', 'RH', 'AH'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AirQuality.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9357, 11)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AirQuality.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "AQ = pd.DataFrame(AirQuality.loc[:, \"CO(GT)\": \"T\"]) #RH and AH should be removed from input matrix and RH is used as Target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO(GT)</th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>NMHC(GT)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>NO2(GT)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1360</td>\n",
       "      <td>150</td>\n",
       "      <td>11.9</td>\n",
       "      <td>1046</td>\n",
       "      <td>166</td>\n",
       "      <td>1056</td>\n",
       "      <td>113</td>\n",
       "      <td>1692</td>\n",
       "      <td>1268</td>\n",
       "      <td>13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1292</td>\n",
       "      <td>112</td>\n",
       "      <td>9.4</td>\n",
       "      <td>955</td>\n",
       "      <td>103</td>\n",
       "      <td>1174</td>\n",
       "      <td>92</td>\n",
       "      <td>1559</td>\n",
       "      <td>972</td>\n",
       "      <td>13.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1402</td>\n",
       "      <td>88</td>\n",
       "      <td>9.0</td>\n",
       "      <td>939</td>\n",
       "      <td>131</td>\n",
       "      <td>1140</td>\n",
       "      <td>114</td>\n",
       "      <td>1555</td>\n",
       "      <td>1074</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1376</td>\n",
       "      <td>80</td>\n",
       "      <td>9.2</td>\n",
       "      <td>948</td>\n",
       "      <td>172</td>\n",
       "      <td>1092</td>\n",
       "      <td>122</td>\n",
       "      <td>1584</td>\n",
       "      <td>1203</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1272</td>\n",
       "      <td>51</td>\n",
       "      <td>6.5</td>\n",
       "      <td>836</td>\n",
       "      <td>131</td>\n",
       "      <td>1205</td>\n",
       "      <td>116</td>\n",
       "      <td>1490</td>\n",
       "      <td>1110</td>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CO(GT)  PT08.S1(CO)  NMHC(GT)  C6H6(GT)  PT08.S2(NMHC)  NOx(GT)  \\\n",
       "0     2.6         1360       150      11.9           1046      166   \n",
       "1     2.0         1292       112       9.4            955      103   \n",
       "2     2.2         1402        88       9.0            939      131   \n",
       "3     2.2         1376        80       9.2            948      172   \n",
       "4     1.6         1272        51       6.5            836      131   \n",
       "\n",
       "   PT08.S3(NOx)  NO2(GT)  PT08.S4(NO2)  PT08.S5(O3)     T  \n",
       "0          1056      113          1692         1268  13.6  \n",
       "1          1174       92          1559          972  13.3  \n",
       "2          1140      114          1555         1074  11.9  \n",
       "3          1092      122          1584         1203  11.0  \n",
       "4          1205      116          1490         1110  11.2  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AQ.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "Target = np.array(AirQuality[\"RH\"]) #relative humidity is selected as target matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48.9, 47.7, 54. , ..., 18.3, 13.5, 13.1])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (AQ - AQ.mean())/(AQ.max()-AQ.min()) #normalizing input/design matrix since our features have different ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO(GT)</th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>NMHC(GT)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>NO2(GT)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.173702</td>\n",
       "      <td>0.138844</td>\n",
       "      <td>0.222527</td>\n",
       "      <td>0.038052</td>\n",
       "      <td>0.062719</td>\n",
       "      <td>-0.001559</td>\n",
       "      <td>0.090534</td>\n",
       "      <td>0.101576</td>\n",
       "      <td>0.101015</td>\n",
       "      <td>0.107575</td>\n",
       "      <td>0.015624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.170871</td>\n",
       "      <td>0.108487</td>\n",
       "      <td>0.195169</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.025023</td>\n",
       "      <td>-0.039081</td>\n",
       "      <td>0.131464</td>\n",
       "      <td>0.062687</td>\n",
       "      <td>0.056309</td>\n",
       "      <td>-0.001128</td>\n",
       "      <td>0.014398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.171815</td>\n",
       "      <td>0.157594</td>\n",
       "      <td>0.177891</td>\n",
       "      <td>0.027055</td>\n",
       "      <td>0.018395</td>\n",
       "      <td>-0.022404</td>\n",
       "      <td>0.119670</td>\n",
       "      <td>0.103428</td>\n",
       "      <td>0.054965</td>\n",
       "      <td>0.036331</td>\n",
       "      <td>0.008674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.171815</td>\n",
       "      <td>0.145987</td>\n",
       "      <td>0.172131</td>\n",
       "      <td>0.027813</td>\n",
       "      <td>0.022123</td>\n",
       "      <td>0.002015</td>\n",
       "      <td>0.103021</td>\n",
       "      <td>0.118243</td>\n",
       "      <td>0.064713</td>\n",
       "      <td>0.083705</td>\n",
       "      <td>0.004995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.168983</td>\n",
       "      <td>0.099558</td>\n",
       "      <td>0.151253</td>\n",
       "      <td>0.017574</td>\n",
       "      <td>-0.024273</td>\n",
       "      <td>-0.022404</td>\n",
       "      <td>0.142216</td>\n",
       "      <td>0.107132</td>\n",
       "      <td>0.033116</td>\n",
       "      <td>0.049551</td>\n",
       "      <td>0.005812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CO(GT)  PT08.S1(CO)  NMHC(GT)  C6H6(GT)  PT08.S2(NMHC)   NOx(GT)  \\\n",
       "0  0.173702     0.138844  0.222527  0.038052       0.062719 -0.001559   \n",
       "1  0.170871     0.108487  0.195169  0.028572       0.025023 -0.039081   \n",
       "2  0.171815     0.157594  0.177891  0.027055       0.018395 -0.022404   \n",
       "3  0.171815     0.145987  0.172131  0.027813       0.022123  0.002015   \n",
       "4  0.168983     0.099558  0.151253  0.017574      -0.024273 -0.022404   \n",
       "\n",
       "   PT08.S3(NOx)   NO2(GT)  PT08.S4(NO2)  PT08.S5(O3)         T  \n",
       "0      0.090534  0.101576      0.101015     0.107575  0.015624  \n",
       "1      0.131464  0.062687      0.056309    -0.001128  0.014398  \n",
       "2      0.119670  0.103428      0.054965     0.036331  0.008674  \n",
       "3      0.103021  0.118243      0.064713     0.083705  0.004995  \n",
       "4      0.142216  0.107132      0.033116     0.049551  0.005812  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9357,)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.33, random_state = 5) \n",
    "#splitting datas into training set using imported function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6269, 11)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.T # we require input matrix to have training sets across the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 6269)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6269,)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need y_train of dimension 1*m_train where m_train = number of training examples\n",
    "y_train = np.array([y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6269)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#our model needs X validation of dimension (number of features x number validation examples)\n",
    "X_val = X_val.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 3088)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need y_val of dimension 1xm_val = number of training examples\n",
    "y_val = np.array([y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 3088)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining out LR model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#step 1, initalize parameters(w,b)\n",
    "def initialize_parameters(lenw):\n",
    "    w = np.random.randn(1, lenw) #generate matrix of dim(1Xlenw) with random values\n",
    "    # w = np.zeros(1,lenw) generates matrix of dim(1Xlenw) with zeros\n",
    "    b = 0\n",
    "    return w,b\n",
    "\n",
    "#step 2, define Z vector containing linear functions(W*X+b)for each training examples\n",
    "def forward_prop(X,w,b):\n",
    "    z = np.dot(w,X)+b # w--> 1xn, X-->nxm , z -->1xm\n",
    "    return z\n",
    "\n",
    "#step 3, calculate cost function each for values generated by linear functions\n",
    "def cost_function(z,y): # y is acutal value of dim 1xm\n",
    "    m = y.shape[1]\n",
    "    J= 1/(2*m)*np.sum(np.square(z-y))\n",
    "    return J \n",
    "    \n",
    "#step 4, find changes required in w and b with respect to J(back propagation)\n",
    "def back_prop(X,y,z):\n",
    "    #dj/dz = 1/m(z-y)\n",
    "    m =y.shape[1]\n",
    "    dz = (1/m) * (z -y)\n",
    "     #dj/dw = dj/dz * X.Transpose(dz/dw) dw--> 1xn\n",
    "    dw = np.dot(dz, X.T)\n",
    "     #dj/db = sum(dj/dz)i(1-m)\n",
    "    db = np.sum(dz)\n",
    "    return dw, db\n",
    "#step 5, update w and b\n",
    "def gradient_descent_update(w, b, dw, db, learning_rate):\n",
    "        w = w- learning_rate*dw \n",
    "        b = b- learning_rate *db\n",
    "        return w,b \n",
    "def linear_regression_model(X_train, y_train, X_val, y_val, learning_rate, epochs):\n",
    "        lenw = X_train.shape[0]\n",
    "        w,b = initialize_parameters(lenw) #step 1\n",
    "        costs_train = []\n",
    "        m_train = y_train.shape[1]\n",
    "        m_val = y_val.shape[1]\n",
    "        \n",
    "        for i in range (0, epochs):\n",
    "            z_train = forward_prop(X_train, w,b) #step 2\n",
    "            cost_train = cost_function(z_train, y_train) #step 3\n",
    "            dw,db = back_prop(X_train, y_train, z_train) #step 4\n",
    "            w,b = gradient_descent_update(w,b,dw,db,learning_rate) #step 5\n",
    "            \n",
    "            #store training cost in a list for plotting purpose\n",
    "            if i%10 == 0 :# for every tenth iteration store\n",
    "                costs_train.append(cost_train)\n",
    "            #Mean absolute error\n",
    "            MAE_train = (1/m_train)*np.sum(np.abs(z_train-y_train))\n",
    "            \n",
    "            #cost function for validation set, MAE for validation set\n",
    "            z_val = forward_prop(X_val, w,b) #step 2\n",
    "            cost_val = cost_function(z_val, y_val)\n",
    "            MAE_val =(1/m_val)*np.sum(np.abs(z_val-y_val))\n",
    "            \n",
    "            #print out cost_train, cost_val , MAE_train, MAE_val\n",
    "            \n",
    "            print('Epochs ' +str(i)+ '/' +str(epochs)+' : ')\n",
    "            print('Training cost '+str(cost_train)+ '|'+' Validation cost ' +str(cost_val))\n",
    "            print('Training cost '+str(MAE_train)+ '|'+' Validation cost ' +str(MAE_val))\n",
    "            \n",
    "        plt.plot(costs_train)\n",
    "        plt.xlabel('Iteratons(per tens)')\n",
    "        plt.ylabel('Training cost')\n",
    "        plt.title('Learning rate ' +str(learning_rate))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 0/500 : \n",
      "Training cost 2026.167091423257| Validation cost 4875773.50380043\n",
      "Training cost 54.625281712942346| Validation cost 124485.60392419554\n",
      "Epochs 1/500 : \n",
      "Training cost 1433.171933267681| Validation cost 4099495.236213615\n",
      "Training cost 39.17986477689215| Validation cost 99266.46686261051\n",
      "Epochs 2/500 : \n",
      "Training cost 1177.1963131870614| Validation cost 3688910.5524425134\n",
      "Training cost 30.860333813842114| Validation cost 86868.26702474625\n",
      "Epochs 3/500 : \n",
      "Training cost 1046.2216575229602| Validation cost 3416887.6107588354\n",
      "Training cost 26.8200183179474| Validation cost 80391.99934506856\n",
      "Epochs 4/500 : \n",
      "Training cost 963.592273117478| Validation cost 3202784.9398455825\n",
      "Training cost 24.758181175974716| Validation cost 76769.58264120607\n",
      "Epochs 5/500 : \n",
      "Training cost 901.4108317631825| Validation cost 3017876.671584646\n",
      "Training cost 23.638548820266372| Validation cost 74567.45776212148\n",
      "Epochs 6/500 : \n",
      "Training cost 849.3597749194439| Validation cost 2851677.908333912\n",
      "Training cost 22.967224098038262| Validation cost 73106.62687756131\n",
      "Epochs 7/500 : \n",
      "Training cost 803.4751234824964| Validation cost 2700036.726995023\n",
      "Training cost 22.537340414111274| Validation cost 72059.3895502006\n",
      "Epochs 8/500 : \n",
      "Training cost 762.102962810201| Validation cost 2560970.4966593934\n",
      "Training cost 22.236989964668627| Validation cost 71254.26092381252\n",
      "Epochs 9/500 : \n",
      "Training cost 724.4417518999387| Validation cost 2433236.756302639\n",
      "Training cost 22.009749180742375| Validation cost 70604.18447259693\n",
      "Epochs 10/500 : \n",
      "Training cost 690.0156689212818| Validation cost 2315857.480303576\n",
      "Training cost 21.83417270857742| Validation cost 70063.32035868571\n",
      "Epochs 11/500 : \n",
      "Training cost 658.4832869153878| Validation cost 2207968.5589823145\n",
      "Training cost 21.689939882624238| Validation cost 69594.97261371341\n",
      "Epochs 12/500 : \n",
      "Training cost 629.5671218348099| Validation cost 2108775.9767754246\n",
      "Training cost 21.565591249193787| Validation cost 69183.14461412161\n",
      "Epochs 13/500 : \n",
      "Training cost 603.026837853818| Validation cost 2017544.4749806002\n",
      "Training cost 21.457984685301984| Validation cost 68812.87649819406\n",
      "Epochs 14/500 : \n",
      "Training cost 578.6483007042667| Validation cost 1933594.579548921\n",
      "Training cost 21.36107112816311| Validation cost 68473.17446641243\n",
      "Epochs 15/500 : \n",
      "Training cost 556.2384560761602| Validation cost 1856300.8215290841\n",
      "Training cost 21.272588237889394| Validation cost 68167.27139963042\n",
      "Epochs 16/500 : \n",
      "Training cost 535.6224139335989| Validation cost 1785089.4426553552\n",
      "Training cost 21.19260798319906| Validation cost 67883.39874432624\n",
      "Epochs 17/500 : \n",
      "Training cost 516.6414258575201| Validation cost 1719435.4737581883\n",
      "Training cost 21.119873166049356| Validation cost 67614.24925137228\n",
      "Epochs 18/500 : \n",
      "Training cost 499.15127366204615| Validation cost 1658859.4304467808\n",
      "Training cost 21.051618667515413| Validation cost 67357.26896661494\n",
      "Epochs 19/500 : \n",
      "Training cost 483.02088756704933| Validation cost 1602923.8721269225\n",
      "Training cost 20.986802293397915| Validation cost 67116.11185128811\n",
      "Epochs 20/500 : \n",
      "Training cost 468.131120982799| Validation cost 1551229.9973264174\n",
      "Training cost 20.925700293023066| Validation cost 66883.69427066352\n",
      "Epochs 21/500 : \n",
      "Training cost 454.3736488144831| Validation cost 1503414.3794581606\n",
      "Training cost 20.86715784343134| Validation cost 66660.20421640447\n",
      "Epochs 22/500 : \n",
      "Training cost 441.64997117182435| Validation cost 1459145.8980679712\n",
      "Training cost 20.81068519385599| Validation cost 66444.67797679096\n",
      "Epochs 23/500 : \n",
      "Training cost 429.87051033374746| Validation cost 1418122.8892966807\n",
      "Training cost 20.756095781406316| Validation cost 66236.8182551211\n",
      "Epochs 24/500 : \n",
      "Training cost 418.953791485462| Validation cost 1380070.520569224\n",
      "Training cost 20.703136478601806| Validation cost 66035.78255119572\n",
      "Epochs 25/500 : \n",
      "Training cost 408.8256991776482| Validation cost 1344738.3839400008\n",
      "Training cost 20.65160267724548| Validation cost 65838.74880152827\n",
      "Epochs 26/500 : \n",
      "Training cost 399.41880240154467| Validation cost 1311898.29693599\n",
      "Training cost 20.601026183806034| Validation cost 65646.1948010512\n",
      "Epochs 27/500 : \n",
      "Training cost 390.671741902471| Validation cost 1281342.2971225784\n",
      "Training cost 20.551185366786907| Validation cost 65457.810958550384\n",
      "Epochs 28/500 : \n",
      "Training cost 382.5286739695945| Validation cost 1252880.8157201847\n",
      "Training cost 20.50177837441869| Validation cost 65271.72749101477\n",
      "Epochs 29/500 : \n",
      "Training cost 374.93876548154935| Validation cost 1226341.0156680378\n",
      "Training cost 20.452780150328557| Validation cost 65088.415496376074\n",
      "Epochs 30/500 : \n",
      "Training cost 367.8557354732735| Validation cost 1201565.2801175264\n",
      "Training cost 20.404108219060504| Validation cost 64907.750353995696\n",
      "Epochs 31/500 : \n",
      "Training cost 361.23743892812314| Validation cost 1178409.8381800246\n",
      "Training cost 20.355800881156064| Validation cost 64729.01230433683\n",
      "Epochs 32/500 : \n",
      "Training cost 355.0454888967099| Validation cost 1156743.5157024574\n",
      "Training cost 20.30773171888834| Validation cost 64552.006555959175\n",
      "Epochs 33/500 : \n",
      "Training cost 349.24491340427903| Validation cost 1136446.5998132536\n",
      "Training cost 20.259787976108058| Validation cost 64376.79599241991\n",
      "Epochs 34/500 : \n",
      "Training cost 343.8038439354111| Validation cost 1117409.806925429\n",
      "Training cost 20.212188375099522| Validation cost 64202.723524370536\n",
      "Epochs 35/500 : \n",
      "Training cost 338.6932325815383| Validation cost 1099533.3447784234\n",
      "Training cost 20.16475804868622| Validation cost 64030.59370346991\n",
      "Epochs 36/500 : \n",
      "Training cost 333.88659520604676| Validation cost 1082726.0599350405\n",
      "Training cost 20.117497418962312| Validation cost 63860.559470417116\n",
      "Epochs 37/500 : \n",
      "Training cost 329.35977822611244| Validation cost 1066904.6629208284\n",
      "Training cost 20.07045755546686| Validation cost 63691.6878419651\n",
      "Epochs 38/500 : \n",
      "Training cost 325.0907468322196| Validation cost 1051993.0239009438\n",
      "Training cost 20.023527065388343| Validation cost 63523.92839831506\n",
      "Epochs 39/500 : \n",
      "Training cost 321.0593926676038| Validation cost 1037921.5324366359\n",
      "Training cost 19.976696847388073| Validation cost 63357.55234441113\n",
      "Epochs 40/500 : \n",
      "Training cost 317.24735917255515| Validation cost 1024626.5154536536\n",
      "Training cost 19.930112628730104| Validation cost 63192.282656354866\n",
      "Epochs 41/500 : \n",
      "Training cost 313.6378829643313| Validation cost 1012049.7080922697\n",
      "Training cost 19.883844140101054| Validation cost 63028.98309531465\n",
      "Epochs 42/500 : \n",
      "Training cost 310.2156497739092| Validation cost 1000137.7725974454\n",
      "Training cost 19.837787345943635| Validation cost 62867.43142526923\n",
      "Epochs 43/500 : \n",
      "Training cost 306.96666359738936| Validation cost 988841.8608519919\n",
      "Training cost 19.792092576185805| Validation cost 62707.250006600305\n",
      "Epochs 44/500 : \n",
      "Training cost 303.8781278438228| Validation cost 978117.2165593321\n",
      "Training cost 19.746714618795803| Validation cost 62548.84581131787\n",
      "Epochs 45/500 : \n",
      "Training cost 300.93833737373325| Validation cost 967922.8134492019\n",
      "Training cost 19.701606211051523| Validation cost 62391.921727292414\n",
      "Epochs 46/500 : \n",
      "Training cost 298.13658042471485| Validation cost 958221.026212709\n",
      "Training cost 19.656753268413812| Validation cost 62236.28466569868\n",
      "Epochs 47/500 : \n",
      "Training cost 295.4630495131588| Validation cost 948977.3311756349\n",
      "Training cost 19.612092089744284| Validation cost 62081.8796747938\n",
      "Epochs 48/500 : \n",
      "Training cost 292.908760485268| Validation cost 940160.0339935184\n",
      "Training cost 19.56768584109373| Validation cost 61928.709576432666\n",
      "Epochs 49/500 : \n",
      "Training cost 290.46547896686| Validation cost 931740.021901456\n",
      "Training cost 19.52348544305495| Validation cost 61777.0017866861\n",
      "Epochs 50/500 : \n",
      "Training cost 288.12565353073876| Validation cost 923690.5382779862\n",
      "Training cost 19.479590895516026| Validation cost 61626.591037649996\n",
      "Epochs 51/500 : \n",
      "Training cost 285.8823549632994| Validation cost 915986.9774880449\n",
      "Training cost 19.43606113012036| Validation cost 61477.48621560117\n",
      "Epochs 52/500 : \n",
      "Training cost 283.72922106910306| Validation cost 908606.6981566619\n",
      "Training cost 19.39287598609057| Validation cost 61330.031112953875\n",
      "Epochs 53/500 : \n",
      "Training cost 281.6604065039574| Validation cost 901528.8531945838\n",
      "Training cost 19.349922531907783| Validation cost 61184.4721498145\n",
      "Epochs 54/500 : \n",
      "Training cost 279.6705371740533| Validation cost 894734.2350509267\n",
      "Training cost 19.30727682409872| Validation cost 61040.205092242286\n",
      "Epochs 55/500 : \n",
      "Training cost 277.754668781378| Validation cost 888205.1348077247\n",
      "Training cost 19.26497565526608| Validation cost 60897.10587916197\n",
      "Epochs 56/500 : \n",
      "Training cost 275.90824913435443| Validation cost 881925.2138581421\n",
      "Training cost 19.222966657039617| Validation cost 60755.36517108979\n",
      "Epochs 57/500 : \n",
      "Training cost 274.1270838778082| Validation cost 875879.387025365\n",
      "Training cost 19.181293057450414| Validation cost 60615.563133471325\n",
      "Epochs 58/500 : \n",
      "Training cost 272.40730532826655| Validation cost 870053.7160838202\n",
      "Training cost 19.140008518029667| Validation cost 60477.04680004365\n",
      "Epochs 59/500 : \n",
      "Training cost 270.7453441295526| Validation cost 864435.3127394014\n",
      "Training cost 19.099172215441033| Validation cost 60339.894019022075\n",
      "Epochs 60/500 : \n",
      "Training cost 269.13790346992| Validation cost 859012.250211674\n",
      "Training cost 19.05871475337573| Validation cost 60204.08279523546\n",
      "Epochs 61/500 : \n",
      "Training cost 267.5819356258291| Validation cost 853773.4826393916\n",
      "Training cost 19.01865560520625| Validation cost 60069.70904383971\n",
      "Epochs 62/500 : \n",
      "Training cost 266.07462061911826| Validation cost 848708.7716018278\n",
      "Training cost 18.978892104103053| Validation cost 59936.78958743838\n",
      "Epochs 63/500 : \n",
      "Training cost 264.6133467939765| Validation cost 843808.6191130544\n",
      "Training cost 18.93947793542416| Validation cost 59805.83561568567\n",
      "Epochs 64/500 : \n",
      "Training cost 263.19569313796126| Validation cost 839064.2065049929\n",
      "Training cost 18.900534841723356| Validation cost 59677.00161927083\n",
      "Epochs 65/500 : \n",
      "Training cost 261.81941318749716| Validation cost 834467.338668383\n",
      "Training cost 18.862144367382292| Validation cost 59549.85620323017\n",
      "Epochs 66/500 : \n",
      "Training cost 260.4824203729891| Validation cost 830010.3931692218\n",
      "Training cost 18.824132375878413| Validation cost 59423.99152536725\n",
      "Epochs 67/500 : \n",
      "Training cost 259.1827746720171| Validation cost 825686.2738022101\n",
      "Training cost 18.786457110380706| Validation cost 59299.940525003214\n",
      "Epochs 68/500 : \n",
      "Training cost 257.91867045119693| Validation cost 821488.3681826806\n",
      "Training cost 18.749121811956417| Validation cost 59177.67793989238\n",
      "Epochs 69/500 : \n",
      "Training cost 256.6884253882722| Validation cost 817410.5090147739\n",
      "Training cost 18.71217996122748| Validation cost 59056.60471795443\n",
      "Epochs 70/500 : \n",
      "Training cost 255.490470375987| Validation cost 813446.9387065732\n",
      "Training cost 18.675644705437715| Validation cost 58937.04561567185\n",
      "Epochs 71/500 : \n",
      "Training cost 254.3233403183385| Validation cost 809592.2770328573\n",
      "Training cost 18.63949445376312| Validation cost 58819.19863763932\n",
      "Epochs 72/500 : \n",
      "Training cost 253.18566573803184| Validation cost 805841.491573323\n",
      "Training cost 18.603741459230136| Validation cost 58702.786213593405\n",
      "Epochs 73/500 : \n",
      "Training cost 252.07616512141993| Validation cost 802189.8706788335\n",
      "Training cost 18.568415475157636| Validation cost 58587.50252386686\n",
      "Epochs 74/500 : \n",
      "Training cost 250.99363793398496| Validation cost 798632.9987406975\n",
      "Training cost 18.533459953552807| Validation cost 58473.49904726197\n",
      "Epochs 75/500 : \n",
      "Training cost 249.9369582455641| Validation cost 795166.7335583763\n",
      "Training cost 18.499088151947664| Validation cost 58360.635952776414\n",
      "Epochs 76/500 : \n",
      "Training cost 248.90506891010762| Validation cost 791787.1856195446\n",
      "Training cost 18.465169537148252| Validation cost 58248.860823316594\n",
      "Epochs 77/500 : \n",
      "Training cost 247.8969762498204| Validation cost 788490.6991232602\n",
      "Training cost 18.431681593247344| Validation cost 58138.636453373\n",
      "Epochs 78/500 : \n",
      "Training cost 246.91174519813876| Validation cost 785273.8345923075\n",
      "Training cost 18.398666584334944| Validation cost 58030.110720717086\n",
      "Epochs 79/500 : \n",
      "Training cost 245.94849486017145| Validation cost 782133.3529346645\n",
      "Training cost 18.366019993995838| Validation cost 57922.87038486713\n",
      "Epochs 80/500 : \n",
      "Training cost 245.00639445302176| Validation cost 779066.2008266879\n",
      "Training cost 18.333727119031625| Validation cost 57816.66377630833\n",
      "Epochs 81/500 : \n",
      "Training cost 244.08465959185062| Validation cost 776069.4973020842\n",
      "Training cost 18.301823102845912| Validation cost 57711.878245047905\n",
      "Epochs 82/500 : \n",
      "Training cost 243.18254889066557| Validation cost 773140.5214411698\n",
      "Training cost 18.27043940951772| Validation cost 57608.277063192814\n",
      "Epochs 83/500 : \n",
      "Training cost 242.29936084965496| Validation cost 770276.701064405\n",
      "Training cost 18.239491899070913| Validation cost 57505.9662522895\n",
      "Epochs 84/500 : \n",
      "Training cost 241.43443100346346| Validation cost 767475.6023428135\n",
      "Training cost 18.208877091720606| Validation cost 57405.02466482549\n",
      "Epochs 85/500 : \n",
      "Training cost 240.58712930714447| Validation cost 764734.9202457177\n",
      "Training cost 18.17862884275145| Validation cost 57306.31432388227\n",
      "Epochs 86/500 : \n",
      "Training cost 239.75685773864356| Validation cost 762052.4697533667\n",
      "Training cost 18.14871743230369| Validation cost 57209.283455007724\n",
      "Epochs 87/500 : \n",
      "Training cost 238.943048098601| Validation cost 759426.1777684873\n",
      "Training cost 18.119120519015162| Validation cost 57113.507834392236\n",
      "Epochs 88/500 : \n",
      "Training cost 238.14515999000648| Validation cost 756854.0756666918\n",
      "Training cost 18.089924433926036| Validation cost 57019.1788637475\n",
      "Epochs 89/500 : \n",
      "Training cost 237.362678961831| Validation cost 754334.292431019\n",
      "Training cost 18.061101439563984| Validation cost 56926.51559568734\n",
      "Epochs 90/500 : \n",
      "Training cost 236.59511480220397| Validation cost 751865.0483207651\n",
      "Training cost 18.032582077947804| Validation cost 56834.7492408003\n",
      "Epochs 91/500 : \n",
      "Training cost 235.84199996801462| Validation cost 749444.6490291741\n",
      "Training cost 18.00444061420516| Validation cost 56744.136117191665\n",
      "Epochs 92/500 : \n",
      "Training cost 235.10288813900473| Validation cost 747071.4802885994\n",
      "Training cost 17.97658519102322| Validation cost 56654.45092070529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 93/500 : \n",
      "Training cost 234.3773528855044| Validation cost 744744.0028853962\n",
      "Training cost 17.949018868973344| Validation cost 56565.76574204974\n",
      "Epochs 94/500 : \n",
      "Training cost 233.66498643994123| Validation cost 742460.7480501508\n",
      "Training cost 17.921793337198327| Validation cost 56478.32523189098\n",
      "Epochs 95/500 : \n",
      "Training cost 232.96539856314652| Validation cost 740220.3131918693\n",
      "Training cost 17.89507547999254| Validation cost 56391.66242268821\n",
      "Epochs 96/500 : \n",
      "Training cost 232.27821549729111| Validation cost 738021.3579475202\n",
      "Training cost 17.86876815973945| Validation cost 56305.843580320965\n",
      "Epochs 97/500 : \n",
      "Training cost 231.60307899802083| Validation cost 735862.6005208229\n",
      "Training cost 17.84272995324117| Validation cost 56221.10206180791\n",
      "Epochs 98/500 : \n",
      "Training cost 230.9396454390274| Validation cost 733742.8142864706\n",
      "Training cost 17.8169857080344| Validation cost 56137.32256591056\n",
      "Epochs 99/500 : \n",
      "Training cost 230.28758498290063| Validation cost 731660.8246380374\n",
      "Training cost 17.791524671342508| Validation cost 56054.33526121619\n",
      "Epochs 100/500 : \n",
      "Training cost 229.64658081265594| Validation cost 729615.5060597355\n",
      "Training cost 17.766284903142115| Validation cost 55972.25361473887\n",
      "Epochs 101/500 : \n",
      "Training cost 229.016328418837| Validation cost 727605.7794038866\n",
      "Training cost 17.741329801842085| Validation cost 55891.49763833021\n",
      "Epochs 102/500 : \n",
      "Training cost 228.39653493754295| Validation cost 725630.609357558\n",
      "Training cost 17.716705941607863| Validation cost 55811.679132372214\n",
      "Epochs 103/500 : \n",
      "Training cost 227.78691853514982| Validation cost 723689.0020832332\n",
      "Training cost 17.692343103166884| Validation cost 55732.71278602851\n",
      "Epochs 104/500 : \n",
      "Training cost 227.1872078358657| Validation cost 721780.0030196942\n",
      "Training cost 17.66827371096373| Validation cost 55654.86821334038\n",
      "Epochs 105/500 : \n",
      "Training cost 226.5971413886065| Validation cost 719902.694830468\n",
      "Training cost 17.64440835113208| Validation cost 55577.92528890293\n",
      "Epochs 106/500 : \n",
      "Training cost 226.01646716998508| Validation cost 718056.1954882841\n",
      "Training cost 17.620815045081805| Validation cost 55502.37427842018\n",
      "Epochs 107/500 : \n",
      "Training cost 225.44494212049344| Validation cost 716239.6564849584\n",
      "Training cost 17.597560772866096| Validation cost 55427.58243749592\n",
      "Epochs 108/500 : \n",
      "Training cost 224.88233171121036| Validation cost 714452.2611570266\n",
      "Training cost 17.57465531760554| Validation cost 55353.79374290994\n",
      "Epochs 109/500 : \n",
      "Training cost 224.32840953860313| Validation cost 712693.2231182656\n",
      "Training cost 17.552035247912055| Validation cost 55280.96104995658\n",
      "Epochs 110/500 : \n",
      "Training cost 223.78295694520367| Validation cost 710961.7847909804\n",
      "Training cost 17.52966577948896| Validation cost 55209.22811011609\n",
      "Epochs 111/500 : \n",
      "Training cost 223.24576266413155| Validation cost 709257.2160286227\n",
      "Training cost 17.507524725378506| Validation cost 55138.523110337206\n",
      "Epochs 112/500 : \n",
      "Training cost 222.7166224856129| Validation cost 707578.8128229211\n",
      "Training cost 17.4856028398101| Validation cost 55068.78515116618\n",
      "Epochs 113/500 : \n",
      "Training cost 222.19533894380444| Validation cost 705925.896089271\n",
      "Training cost 17.46394282612046| Validation cost 54999.78013208129\n",
      "Epochs 114/500 : \n",
      "Training cost 221.6817210223753| Validation cost 704297.8105246477\n",
      "Training cost 17.44260029411427| Validation cost 54931.544136565266\n",
      "Epochs 115/500 : \n",
      "Training cost 221.1755838774343| Validation cost 702693.9235327784\n",
      "Training cost 17.42158708374307| Validation cost 54863.94180968711\n",
      "Epochs 116/500 : \n",
      "Training cost 220.67674857650832| Validation cost 701113.6242117361\n",
      "Training cost 17.40076489389006| Validation cost 54797.06691492623\n",
      "Epochs 117/500 : \n",
      "Training cost 220.1850418523889| Validation cost 699556.322399515\n",
      "Training cost 17.380221574755627| Validation cost 54731.21722463775\n",
      "Epochs 118/500 : \n",
      "Training cost 219.7002958707621| Validation cost 698021.4477735021\n",
      "Training cost 17.359946259184024| Validation cost 54665.89681842165\n",
      "Epochs 119/500 : \n",
      "Training cost 219.22234801062967| Validation cost 696508.4490000925\n",
      "Training cost 17.339851386298598| Validation cost 54601.27883052433\n",
      "Epochs 120/500 : \n",
      "Training cost 218.75104065661094| Validation cost 695016.7929309867\n",
      "Training cost 17.319966729371604| Validation cost 54537.41005089405\n",
      "Epochs 121/500 : \n",
      "Training cost 218.28622100229006| Validation cost 693545.9638429935\n",
      "Training cost 17.30028325856446| Validation cost 54474.6191521017\n",
      "Epochs 122/500 : \n",
      "Training cost 217.82774086384336| Validation cost 692095.4627184044\n",
      "Training cost 17.280860069614988| Validation cost 54412.79691368961\n",
      "Epochs 123/500 : \n",
      "Training cost 217.37545650324302| Validation cost 690664.8065632356\n",
      "Training cost 17.261609609576247| Validation cost 54351.6893009884\n",
      "Epochs 124/500 : \n",
      "Training cost 216.92922846039073| Validation cost 689253.5277608482\n",
      "Training cost 17.24261517744331| Validation cost 54291.19578959892\n",
      "Epochs 125/500 : \n",
      "Training cost 216.48892139358708| Validation cost 687861.1734586434\n",
      "Training cost 17.223793980104283| Validation cost 54231.618368780255\n",
      "Epochs 126/500 : \n",
      "Training cost 216.05440392779067| Validation cost 686487.3049857088\n",
      "Training cost 17.205197793241688| Validation cost 54172.6520905067\n",
      "Epochs 127/500 : \n",
      "Training cost 215.62554851016236| Validation cost 685131.4972994532\n",
      "Training cost 17.1868057763829| Validation cost 54114.650380507934\n",
      "Epochs 128/500 : \n",
      "Training cost 215.2022312724326| Validation cost 683793.3384594113\n",
      "Training cost 17.168579470658354| Validation cost 54057.2987092669\n",
      "Epochs 129/500 : \n",
      "Training cost 214.78433189966302| Validation cost 682472.4291265416\n",
      "Training cost 17.150510699759437| Validation cost 54000.49095452587\n",
      "Epochs 130/500 : \n",
      "Training cost 214.3717335050086| Validation cost 681168.382086457\n",
      "Training cost 17.132640520352453| Validation cost 53944.234105760166\n",
      "Epochs 131/500 : \n",
      "Training cost 213.96432251011527| Validation cost 679880.8217951496\n",
      "Training cost 17.114956163744882| Validation cost 53888.600231642646\n",
      "Epochs 132/500 : \n",
      "Training cost 213.56198853081756| Validation cost 678609.38394587\n",
      "Training cost 17.097485214760148| Validation cost 53833.57707201225\n",
      "Epochs 133/500 : \n",
      "Training cost 213.16462426782377| Validation cost 677353.7150559188\n",
      "Training cost 17.080230149652742| Validation cost 53779.12028065656\n",
      "Epochs 134/500 : \n",
      "Training cost 212.77212540210041| Validation cost 676113.4720722004\n",
      "Training cost 17.063145206197703| Validation cost 53725.1169529419\n",
      "Epochs 135/500 : \n",
      "Training cost 212.38439049468946| Validation cost 674888.3219944641\n",
      "Training cost 17.04628828706252| Validation cost 53671.65846471986\n",
      "Epochs 136/500 : \n",
      "Training cost 212.00132089070988| Validation cost 673677.9415152369\n",
      "Training cost 17.02960479456026| Validation cost 53618.68501824772\n",
      "Epochs 137/500 : \n",
      "Training cost 211.62282062731362| Validation cost 672482.0166755188\n",
      "Training cost 17.013090886799365| Validation cost 53566.20386416209\n",
      "Epochs 138/500 : \n",
      "Training cost 211.2487963453825| Validation cost 671300.2425353786\n",
      "Training cost 16.996732601298387| Validation cost 53514.12544645303\n",
      "Epochs 139/500 : \n",
      "Training cost 210.87915720476676| Validation cost 670132.3228586377\n",
      "Training cost 16.98056902026702| Validation cost 53462.64911493256\n",
      "Epochs 140/500 : \n",
      "Training cost 210.5138148028805| Validation cost 668977.9698108968\n",
      "Training cost 16.964661534365387| Validation cost 53411.74390284798\n",
      "Epochs 141/500 : \n",
      "Training cost 210.15268309648124| Validation cost 667836.903670195\n",
      "Training cost 16.948905405723046| Validation cost 53361.296049080396\n",
      "Epochs 142/500 : \n",
      "Training cost 209.79567832647265| Validation cost 666708.8525496521\n",
      "Training cost 16.933301082539547| Validation cost 53311.337265386406\n",
      "Epochs 143/500 : \n",
      "Training cost 209.44271894558057| Validation cost 665593.5521314695\n",
      "Training cost 16.917815878167186| Validation cost 53261.72578997006\n",
      "Epochs 144/500 : \n",
      "Training cost 209.09372554876072| Validation cost 664490.745411726\n",
      "Training cost 16.90247122588904| Validation cost 53212.63653525489\n",
      "Epochs 145/500 : \n",
      "Training cost 208.74862080620818| Validation cost 663400.1824554163\n",
      "Training cost 16.88728452587366| Validation cost 53164.37947083534\n",
      "Epochs 146/500 : \n",
      "Training cost 208.40732939884396| Validation cost 662321.6201612388\n",
      "Training cost 16.872215946595738| Validation cost 53116.55067388141\n",
      "Epochs 147/500 : \n",
      "Training cost 208.06977795616393| Validation cost 661254.822035647\n",
      "Training cost 16.85728689342872| Validation cost 53069.30905771461\n",
      "Epochs 148/500 : \n",
      "Training cost 207.73589499634195| Validation cost 660199.5579757262\n",
      "Training cost 16.842492522296595| Validation cost 53022.65999224242\n",
      "Epochs 149/500 : \n",
      "Training cost 207.40561086848442| Validation cost 659155.6040604727\n",
      "Training cost 16.827831430950752| Validation cost 52976.31445227709\n",
      "Epochs 150/500 : \n",
      "Training cost 207.07885769694118| Validation cost 658122.7423500812\n",
      "Training cost 16.81330324436637| Validation cost 52930.31033023553\n",
      "Epochs 151/500 : \n",
      "Training cost 206.75556932758232| Validation cost 657100.7606928698\n",
      "Training cost 16.798930642523633| Validation cost 52884.60519567184\n",
      "Epochs 152/500 : \n",
      "Training cost 206.4356812759558| Validation cost 656089.4525394909\n",
      "Training cost 16.78468566511923| Validation cost 52839.29063429715\n",
      "Epochs 153/500 : \n",
      "Training cost 206.1191306772455| Validation cost 655088.6167641011\n",
      "Training cost 16.770554855753577| Validation cost 52794.5235883545\n",
      "Epochs 154/500 : \n",
      "Training cost 205.80585623795443| Validation cost 654098.0574921735\n",
      "Training cost 16.756541614507828| Validation cost 52750.23532372462\n",
      "Epochs 155/500 : \n",
      "Training cost 205.49579818924116| Validation cost 653117.5839346618\n",
      "Training cost 16.74264223636406| Validation cost 52706.399470479555\n",
      "Epochs 156/500 : \n",
      "Training cost 205.188898241841| Validation cost 652147.0102282376\n",
      "Training cost 16.728846406829202| Validation cost 52662.91187236937\n",
      "Epochs 157/500 : \n",
      "Training cost 204.88509954250944| Validation cost 651186.1552813353\n",
      "Training cost 16.715175911131535| Validation cost 52619.75353849965\n",
      "Epochs 158/500 : \n",
      "Training cost 204.58434663192543| Validation cost 650234.8426257573\n",
      "Training cost 16.70162419547722| Validation cost 52576.9319868522\n",
      "Epochs 159/500 : \n",
      "Training cost 204.28658540399726| Validation cost 649292.9002736036\n",
      "Training cost 16.68819363501333| Validation cost 52534.41541837903\n",
      "Epochs 160/500 : \n",
      "Training cost 203.99176306651685| Validation cost 648360.1605792993\n",
      "Training cost 16.674863458506476| Validation cost 52492.139023451964\n",
      "Epochs 161/500 : \n",
      "Training cost 203.699828103109| Validation cost 647436.4601065116\n",
      "Training cost 16.66165388008163| Validation cost 52450.17899101545\n",
      "Epochs 162/500 : \n",
      "Training cost 203.41073023642758| Validation cost 646521.6394997522\n",
      "Training cost 16.64858166802826| Validation cost 52408.5412060592\n",
      "Epochs 163/500 : \n",
      "Training cost 203.1244203925505| Validation cost 645615.5433604715\n",
      "Training cost 16.635630809973595| Validation cost 52367.20708070368\n",
      "Epochs 164/500 : \n",
      "Training cost 202.840850666528| Validation cost 644718.0201274687\n",
      "Training cost 16.622805672565015| Validation cost 52326.203188448344\n",
      "Epochs 165/500 : \n",
      "Training cost 202.55997428904374| Validation cost 643828.9219614386\n",
      "Training cost 16.61009843595355| Validation cost 52285.51342324457\n",
      "Epochs 166/500 : \n",
      "Training cost 202.2817455941444| Validation cost 642948.1046334925\n",
      "Training cost 16.597521670129666| Validation cost 52245.23745426392\n",
      "Epochs 167/500 : \n",
      "Training cost 202.00611998800173| Validation cost 642075.4274174972\n",
      "Training cost 16.585069181410528| Validation cost 52205.36136047033\n",
      "Epochs 168/500 : \n",
      "Training cost 201.7330539186677| Validation cost 641210.7529860821\n",
      "Training cost 16.572736849950672| Validation cost 52165.890870480114\n",
      "Epochs 169/500 : \n",
      "Training cost 201.4625048467889| Validation cost 640353.9473101697\n",
      "Training cost 16.56051011101353| Validation cost 52126.63241822036\n",
      "Epochs 170/500 : \n",
      "Training cost 201.19443121724373| Validation cost 639504.879561897\n",
      "Training cost 16.548389918180167| Validation cost 52088.07500790234\n",
      "Epochs 171/500 : \n",
      "Training cost 200.92879243167218| Validation cost 638663.422020795\n",
      "Training cost 16.536345188678837| Validation cost 52049.912432424695\n",
      "Epochs 172/500 : \n",
      "Training cost 200.6655488218651| Validation cost 637829.4499831041\n",
      "Training cost 16.524377298148824| Validation cost 52012.11880929503\n",
      "Epochs 173/500 : \n",
      "Training cost 200.4046616239836| Validation cost 637002.8416741064\n",
      "Training cost 16.512535821962146| Validation cost 51974.69995501038\n",
      "Epochs 174/500 : \n",
      "Training cost 200.1460929535803| Validation cost 636183.4781633613\n",
      "Training cost 16.50077245420242| Validation cost 51937.49745599142\n",
      "Epochs 175/500 : \n",
      "Training cost 199.8898057813937| Validation cost 635371.2432827371\n",
      "Training cost 16.489106253280973| Validation cost 51900.57413794735\n",
      "Epochs 176/500 : \n",
      "Training cost 199.63576390989013| Validation cost 634566.0235471344\n",
      "Training cost 16.477545187943523| Validation cost 51863.981148411825\n",
      "Epochs 177/500 : \n",
      "Training cost 199.38393195052777| Validation cost 633767.7080778021\n",
      "Training cost 16.466097864052614| Validation cost 51827.57544457827\n",
      "Epochs 178/500 : \n",
      "Training cost 199.1342753017175| Validation cost 632976.1885281517\n",
      "Training cost 16.45472989786231| Validation cost 51791.354144606\n",
      "Epochs 179/500 : \n",
      "Training cost 198.88676012745822| Validation cost 632191.3590119781\n",
      "Training cost 16.443431615950125| Validation cost 51755.315479246376\n",
      "Epochs 180/500 : \n",
      "Training cost 198.6413533366228| Validation cost 631413.1160340012\n",
      "Training cost 16.432207310763008| Validation cost 51719.481690998255\n",
      "Epochs 181/500 : \n",
      "Training cost 198.39802256287462| Validation cost 630641.3584226419\n",
      "Training cost 16.421095019329393| Validation cost 51683.862245046475\n",
      "Epochs 182/500 : \n",
      "Training cost 198.15673614519147| Validation cost 629875.9872649575\n",
      "Training cost 16.41005093271112| Validation cost 51648.51572201286\n",
      "Epochs 183/500 : \n",
      "Training cost 197.91746310897943| Validation cost 629116.9058436537\n",
      "Training cost 16.399059998646525| Validation cost 51613.37407908107\n",
      "Epochs 184/500 : \n",
      "Training cost 197.6801731477544| Validation cost 628364.0195761041\n",
      "Training cost 16.38813362399365| Validation cost 51578.66173761101\n",
      "Epochs 185/500 : \n",
      "Training cost 197.44483660537546| Validation cost 627617.2359553038\n",
      "Training cost 16.37726479874971| Validation cost 51544.18778243533\n",
      "Epochs 186/500 : \n",
      "Training cost 197.2114244588099| Validation cost 626876.4644926896\n",
      "Training cost 16.366454402643438| Validation cost 51510.07076765061\n",
      "Epochs 187/500 : \n",
      "Training cost 196.97990830141362| Validation cost 626141.6166627641\n",
      "Training cost 16.35572942585234| Validation cost 51476.36243851519\n",
      "Epochs 188/500 : \n",
      "Training cost 196.75026032671028| Validation cost 625412.6058494562\n",
      "Training cost 16.345104479457806| Validation cost 51442.82134528411\n",
      "Epochs 189/500 : \n",
      "Training cost 196.5224533126523| Validation cost 624689.347294161\n",
      "Training cost 16.3345378489007| Validation cost 51409.488002406244\n",
      "Epochs 190/500 : \n",
      "Training cost 196.29646060634883| Validation cost 623971.7580454024\n",
      "Training cost 16.32403252975607| Validation cost 51376.318017092795\n",
      "Epochs 191/500 : \n",
      "Training cost 196.07225610924598| Validation cost 623259.756910057\n",
      "Training cost 16.3136098275017| Validation cost 51343.44305900343\n",
      "Epochs 192/500 : \n",
      "Training cost 195.84981426274325| Validation cost 622553.2644060936\n",
      "Training cost 16.303267172883704| Validation cost 51310.75151188457\n",
      "Epochs 193/500 : \n",
      "Training cost 195.6291100342346| Validation cost 621852.2027167698\n",
      "Training cost 16.29301035582577| Validation cost 51278.25112650716\n",
      "Epochs 194/500 : \n",
      "Training cost 195.41011890355867| Validation cost 621156.4956462383\n",
      "Training cost 16.282835457879475| Validation cost 51246.01962654586\n",
      "Epochs 195/500 : \n",
      "Training cost 195.19281684984568| Validation cost 620466.0685765187\n",
      "Training cost 16.272749020632272| Validation cost 51213.96313091731\n",
      "Epochs 196/500 : \n",
      "Training cost 194.9771803387491| Validation cost 619780.8484257828\n",
      "Training cost 16.262748010432873| Validation cost 51182.19890200415\n",
      "Epochs 197/500 : \n",
      "Training cost 194.76318631004915| Validation cost 619100.7636079136\n",
      "Training cost 16.2528097190157| Validation cost 51150.653860384555\n",
      "Epochs 198/500 : \n",
      "Training cost 194.55081216561692| Validation cost 618425.7439932935\n",
      "Training cost 16.242940618146353| Validation cost 51119.31743490597\n",
      "Epochs 199/500 : \n",
      "Training cost 194.34003575772707| Validation cost 617755.7208707805\n",
      "Training cost 16.23313669226305| Validation cost 51088.12392566298\n",
      "Epochs 200/500 : \n",
      "Training cost 194.13083537770933| Validation cost 617090.626910834\n",
      "Training cost 16.223400395733687| Validation cost 51057.0764898748\n",
      "Epochs 201/500 : \n",
      "Training cost 193.92318974492687| Validation cost 616430.3961297504\n",
      "Training cost 16.213727717741012| Validation cost 51026.22499107383\n",
      "Epochs 202/500 : \n",
      "Training cost 193.71707799607222| Validation cost 615774.9638549739\n",
      "Training cost 16.204134670256472| Validation cost 50995.51243600919\n",
      "Epochs 203/500 : \n",
      "Training cost 193.51247967477082| Validation cost 615124.2666914444\n",
      "Training cost 16.194631144519477| Validation cost 50965.01279458449\n",
      "Epochs 204/500 : \n",
      "Training cost 193.3093747214819| Validation cost 614478.2424889514\n",
      "Training cost 16.185195492353028| Validation cost 50934.78129803085\n",
      "Epochs 205/500 : \n",
      "Training cost 193.10774346368845| Validation cost 613836.8303104569\n",
      "Training cost 16.17580865783719| Validation cost 50904.744220962086\n",
      "Epochs 206/500 : \n",
      "Training cost 192.90756660636632| Validation cost 613199.9704013609\n",
      "Training cost 16.166493071633568| Validation cost 50874.93322058345\n",
      "Epochs 207/500 : \n",
      "Training cost 192.70882522272487| Validation cost 612567.604159673\n",
      "Training cost 16.157235953680555| Validation cost 50845.33098372245\n",
      "Epochs 208/500 : \n",
      "Training cost 192.51150074520982| Validation cost 611939.6741070647\n",
      "Training cost 16.148072841889086| Validation cost 50816.0142064276\n",
      "Epochs 209/500 : \n",
      "Training cost 192.31557495676068| Validation cost 611316.1238607746\n",
      "Training cost 16.13895386809101| Validation cost 50786.94672938294\n",
      "Epochs 210/500 : \n",
      "Training cost 192.12102998231526| Validation cost 610696.8981063319\n",
      "Training cost 16.129888133601234| Validation cost 50758.28575993749\n",
      "Epochs 211/500 : \n",
      "Training cost 191.9278482805529| Validation cost 610081.9425710815\n",
      "Training cost 16.120881838346378| Validation cost 50729.99936758312\n",
      "Epochs 212/500 : \n",
      "Training cost 191.7360126358696| Validation cost 609471.2039984779\n",
      "Training cost 16.111950167380087| Validation cost 50701.968109255846\n",
      "Epochs 213/500 : \n",
      "Training cost 191.54550615057812| Validation cost 608864.6301231261\n",
      "Training cost 16.10307661925255| Validation cost 50674.1629001254\n",
      "Epochs 214/500 : \n",
      "Training cost 191.3563122373257| Validation cost 608262.1696465441\n",
      "Training cost 16.094262732442175| Validation cost 50646.50113983727\n",
      "Epochs 215/500 : \n",
      "Training cost 191.16841461172308| Validation cost 607663.7722136264\n",
      "Training cost 16.085504336015106| Validation cost 50618.95450564485\n",
      "Epochs 216/500 : \n",
      "Training cost 190.9817972851784| Validation cost 607069.3883897832\n",
      "Training cost 16.076800132271725| Validation cost 50591.56219914903\n",
      "Epochs 217/500 : \n",
      "Training cost 190.79644455792933| Validation cost 606478.9696387352\n",
      "Training cost 16.0681381402135| Validation cost 50564.37357267895\n",
      "Epochs 218/500 : \n",
      "Training cost 190.6123410122685| Validation cost 605892.4683009447\n",
      "Training cost 16.05951377534328| Validation cost 50537.39309198345\n",
      "Epochs 219/500 : \n",
      "Training cost 190.429471505955| Validation cost 605309.8375726589\n",
      "Training cost 16.05094291061661| Validation cost 50510.52258908802\n",
      "Epochs 220/500 : \n",
      "Training cost 190.24782116580695| Validation cost 604731.0314855524\n",
      "Training cost 16.04241905918997| Validation cost 50483.80858984799\n",
      "Epochs 221/500 : \n",
      "Training cost 190.06737538147036| Validation cost 604156.0048869407\n",
      "Training cost 16.033977310061925| Validation cost 50457.231330426046\n",
      "Epochs 222/500 : \n",
      "Training cost 189.88811979935778| Validation cost 603584.7134205583\n",
      "Training cost 16.025612385251044| Validation cost 50430.81085570855\n",
      "Epochs 223/500 : \n",
      "Training cost 189.71004031675224| Validation cost 603017.1135078727\n",
      "Training cost 16.017301910878814| Validation cost 50404.56132251897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 224/500 : \n",
      "Training cost 189.53312307607172| Validation cost 602453.1623299262\n",
      "Training cost 16.009033704175543| Validation cost 50378.58937637382\n",
      "Epochs 225/500 : \n",
      "Training cost 189.35735445928876| Validation cost 601892.8178096828\n",
      "Training cost 16.000802219403226| Validation cost 50352.80952491271\n",
      "Epochs 226/500 : \n",
      "Training cost 189.18272108250136| Validation cost 601336.038594869\n",
      "Training cost 15.992627927395048| Validation cost 50327.21928104783\n",
      "Epochs 227/500 : \n",
      "Training cost 189.00920979064958| Validation cost 600782.7840412899\n",
      "Training cost 15.984506407659584| Validation cost 50301.839033633296\n",
      "Epochs 228/500 : \n",
      "Training cost 188.8368076523749| Validation cost 600233.0141966077\n",
      "Training cost 15.976425166903919| Validation cost 50276.68444686638\n",
      "Epochs 229/500 : \n",
      "Training cost 188.66550195501637| Validation cost 599686.6897845687\n",
      "Training cost 15.968391983573488| Validation cost 50251.63440353541\n",
      "Epochs 230/500 : \n",
      "Training cost 188.4952801997415| Validation cost 599143.7721896615\n",
      "Training cost 15.960419103434024| Validation cost 50226.71804453319\n",
      "Epochs 231/500 : \n",
      "Training cost 188.3261300968059| Validation cost 598604.2234422003\n",
      "Training cost 15.952511230055775| Validation cost 50201.929471387135\n",
      "Epochs 232/500 : \n",
      "Training cost 188.15803956093927| Validation cost 598068.006203811\n",
      "Training cost 15.944639944313113| Validation cost 50177.238051373446\n",
      "Epochs 233/500 : \n",
      "Training cost 187.99099670685368| Validation cost 597535.0837533154\n",
      "Training cost 15.93682407410381| Validation cost 50152.75777613104\n",
      "Epochs 234/500 : \n",
      "Training cost 187.82498984486998| Validation cost 597005.419972997\n",
      "Training cost 15.929041048995414| Validation cost 50128.416177038715\n",
      "Epochs 235/500 : \n",
      "Training cost 187.66000747665933| Validation cost 596478.9793352406\n",
      "Training cost 15.921319961922675| Validation cost 50104.2457340713\n",
      "Epochs 236/500 : \n",
      "Training cost 187.496038291097| Validation cost 595955.7268895276\n",
      "Training cost 15.91365170099829| Validation cost 50080.212355359945\n",
      "Epochs 237/500 : \n",
      "Training cost 187.3330711602238| Validation cost 595435.6282497863\n",
      "Training cost 15.906019082597616| Validation cost 50056.30903489199\n",
      "Epochs 238/500 : \n",
      "Training cost 187.1710951353132| Validation cost 594918.6495820748\n",
      "Training cost 15.898440858550844| Validation cost 50032.5106740663\n",
      "Epochs 239/500 : \n",
      "Training cost 187.01009944304064| Validation cost 594404.7575925975\n",
      "Training cost 15.890894603653667| Validation cost 50008.81003303544\n",
      "Epochs 240/500 : \n",
      "Training cost 186.85007348175168| Validation cost 593893.919516037\n",
      "Training cost 15.883388458070312| Validation cost 49985.202537609366\n",
      "Epochs 241/500 : \n",
      "Training cost 186.69100681782706| Validation cost 593386.1031041958\n",
      "Training cost 15.87592220425736| Validation cost 49961.69484642296\n",
      "Epochs 242/500 : \n",
      "Training cost 186.53288918214054| Validation cost 592881.2766149382\n",
      "Training cost 15.868498132328298| Validation cost 49938.281988862596\n",
      "Epochs 243/500 : \n",
      "Training cost 186.37571046660833| Validation cost 592379.4088014225\n",
      "Training cost 15.861125465214283| Validation cost 49915.05998730427\n",
      "Epochs 244/500 : \n",
      "Training cost 186.21946072082588| Validation cost 591880.4689016152\n",
      "Training cost 15.853799474697075| Validation cost 49891.98140596815\n",
      "Epochs 245/500 : \n",
      "Training cost 186.06413014879126| Validation cost 591384.4266280793\n",
      "Training cost 15.846517631870627| Validation cost 49868.98927035782\n",
      "Epochs 246/500 : \n",
      "Training cost 185.90970910571073| Validation cost 590891.2521580275\n",
      "Training cost 15.839271540258498| Validation cost 49846.08201614018\n",
      "Epochs 247/500 : \n",
      "Training cost 185.7561880948857| Validation cost 590400.9161236344\n",
      "Training cost 15.832056127575457| Validation cost 49823.25658419586\n",
      "Epochs 248/500 : \n",
      "Training cost 185.6035577646783| Validation cost 589913.3896025971\n",
      "Training cost 15.824892980029679| Validation cost 49800.60409057404\n",
      "Epochs 249/500 : \n",
      "Training cost 185.4518089055526| Validation cost 589428.6441089393\n",
      "Training cost 15.817773700969482| Validation cost 49778.039185578105\n",
      "Epochs 250/500 : \n",
      "Training cost 185.30093244719018| Validation cost 588946.6515840524\n",
      "Training cost 15.810680107869329| Validation cost 49755.56114531573\n",
      "Epochs 251/500 : \n",
      "Training cost 185.15091945567784| Validation cost 588467.3843879623\n",
      "Training cost 15.803618425718426| Validation cost 49733.22201874672\n",
      "Epochs 252/500 : \n",
      "Training cost 185.001761130765| Validation cost 587990.8152908206\n",
      "Training cost 15.796616478096746| Validation cost 49711.14849358664\n",
      "Epochs 253/500 : \n",
      "Training cost 184.85344880318883| Validation cost 587516.9174646109\n",
      "Training cost 15.789665486511218| Validation cost 49689.167294715415\n",
      "Epochs 254/500 : \n",
      "Training cost 184.70597393206566| Validation cost 587045.6644750638\n",
      "Training cost 15.78276431214495| Validation cost 49667.277275231354\n",
      "Epochs 255/500 : \n",
      "Training cost 184.55932810234677| Validation cost 586577.0302737751\n",
      "Training cost 15.77590877329514| Validation cost 49645.476385307295\n",
      "Epochs 256/500 : \n",
      "Training cost 184.4135030223356| Validation cost 586110.9891905218\n",
      "Training cost 15.769106874307179| Validation cost 49623.75074741555\n",
      "Epochs 257/500 : \n",
      "Training cost 184.26849052126647| Validation cost 585647.5159257693\n",
      "Training cost 15.762346130396638| Validation cost 49602.09985456784\n",
      "Epochs 258/500 : \n",
      "Training cost 184.12428254694188| Validation cost 585186.5855433655\n",
      "Training cost 15.755623265260219| Validation cost 49580.547332477865\n",
      "Epochs 259/500 : \n",
      "Training cost 183.98087116342668| Validation cost 584728.1734634133\n",
      "Training cost 15.748936556817219| Validation cost 49559.17073556929\n",
      "Epochs 260/500 : \n",
      "Training cost 183.83824854879836| Validation cost 584272.2554553227\n",
      "Training cost 15.74227729006712| Validation cost 49537.917271300576\n",
      "Epochs 261/500 : \n",
      "Training cost 183.69640699295135| Validation cost 583818.8076310293\n",
      "Training cost 15.735646967759918| Validation cost 49516.865552366275\n",
      "Epochs 262/500 : \n",
      "Training cost 183.5553388954534| Validation cost 583367.8064383811\n",
      "Training cost 15.729049248695533| Validation cost 49495.91538172611\n",
      "Epochs 263/500 : \n",
      "Training cost 183.41503676345386| Validation cost 582919.2286546852\n",
      "Training cost 15.722482422293458| Validation cost 49475.09583028112\n",
      "Epochs 264/500 : \n",
      "Training cost 183.27549320964113| Validation cost 582473.0513804113\n",
      "Training cost 15.715951069422053| Validation cost 49454.3836640072\n",
      "Epochs 265/500 : \n",
      "Training cost 183.1367009502486| Validation cost 582029.2520330471\n",
      "Training cost 15.709457388820526| Validation cost 49433.739969093265\n",
      "Epochs 266/500 : \n",
      "Training cost 182.99865280310757| Validation cost 581587.8083411017\n",
      "Training cost 15.70301057978641| Validation cost 49413.19067942757\n",
      "Epochs 267/500 : \n",
      "Training cost 182.8613416857462| Validation cost 581148.6983382523\n",
      "Training cost 15.69659542447539| Validation cost 49392.71985651902\n",
      "Epochs 268/500 : \n",
      "Training cost 182.7247606135322| Validation cost 580711.9003576294\n",
      "Training cost 15.690204808524319| Validation cost 49372.33408707995\n",
      "Epochs 269/500 : \n",
      "Training cost 182.58890269785994| Validation cost 580277.3930262404\n",
      "Training cost 15.68384228263091| Validation cost 49352.17915964958\n",
      "Epochs 270/500 : \n",
      "Training cost 182.45376114437823| Validation cost 579845.1552595219\n",
      "Training cost 15.677504802562083| Validation cost 49332.13219441331\n",
      "Epochs 271/500 : \n",
      "Training cost 182.31932925126048| Validation cost 579415.1662560231\n",
      "Training cost 15.671191526167942| Validation cost 49312.18603750887\n",
      "Epochs 272/500 : \n",
      "Training cost 182.18560040751345| Validation cost 578987.4054922108\n",
      "Training cost 15.664897298918849| Validation cost 49292.3063221934\n",
      "Epochs 273/500 : \n",
      "Training cost 182.05256809132564| Validation cost 578561.8527173982\n",
      "Training cost 15.658622003625966| Validation cost 49272.499882082295\n",
      "Epochs 274/500 : \n",
      "Training cost 181.92022586845303| Validation cost 578138.4879487909\n",
      "Training cost 15.652373357779696| Validation cost 49252.83931695582\n",
      "Epochs 275/500 : \n",
      "Training cost 181.78856739064142| Validation cost 577717.2914666462\n",
      "Training cost 15.646148503805266| Validation cost 49233.34269815663\n",
      "Epochs 276/500 : \n",
      "Training cost 181.65758639408494| Validation cost 577298.2438095463\n",
      "Training cost 15.639949921863865| Validation cost 49214.01208797379\n",
      "Epochs 277/500 : \n",
      "Training cost 181.5272766979189| Validation cost 576881.3257697772\n",
      "Training cost 15.633783829994364| Validation cost 49194.80473234659\n",
      "Epochs 278/500 : \n",
      "Training cost 181.39763220274642| Validation cost 576466.5183888152\n",
      "Training cost 15.627646183817154| Validation cost 49175.706969996376\n",
      "Epochs 279/500 : \n",
      "Training cost 181.26864688919872| Validation cost 576053.8029529154\n",
      "Training cost 15.62153798337229| Validation cost 49156.794316075015\n",
      "Epochs 280/500 : \n",
      "Training cost 181.14031481652648| Validation cost 575643.1609888\n",
      "Training cost 15.615464932846223| Validation cost 49137.973281879786\n",
      "Epochs 281/500 : \n",
      "Training cost 181.0126301212234| Validation cost 575234.5742594433\n",
      "Training cost 15.609428484220969| Validation cost 49119.25074859169\n",
      "Epochs 282/500 : \n",
      "Training cost 180.88558701567933| Validation cost 574828.0247599523\n",
      "Training cost 15.603427692988479| Validation cost 49100.58604391316\n",
      "Epochs 283/500 : \n",
      "Training cost 180.75917978686388| Validation cost 574423.4947135386\n",
      "Training cost 15.597465538628471| Validation cost 49081.97881541766\n",
      "Epochs 284/500 : \n",
      "Training cost 180.6334027950379| Validation cost 574020.9665675799\n",
      "Training cost 15.591541070822872| Validation cost 49063.42871399749\n",
      "Epochs 285/500 : \n",
      "Training cost 180.50825047249398| Validation cost 573620.4229897689\n",
      "Training cost 15.585643882868089| Validation cost 49045.05956881332\n",
      "Epochs 286/500 : \n",
      "Training cost 180.38371732232358| Validation cost 573221.8468643472\n",
      "Training cost 15.579777079506774| Validation cost 49026.763149678896\n",
      "Epochs 287/500 : \n",
      "Training cost 180.25979791721127| Validation cost 572825.2212884212\n",
      "Training cost 15.573933118109593| Validation cost 49008.56117881931\n",
      "Epochs 288/500 : \n",
      "Training cost 180.13648689825496| Validation cost 572430.5295683597\n",
      "Training cost 15.568105631729548| Validation cost 48990.46644036397\n",
      "Epochs 289/500 : \n",
      "Training cost 180.0137789738109| Validation cost 572037.7552162679\n",
      "Training cost 15.56229452550532| Validation cost 48972.42624763842\n",
      "Epochs 290/500 : \n",
      "Training cost 179.89166891836393| Validation cost 571646.8819465401\n",
      "Training cost 15.556502183554109| Validation cost 48954.44027493133\n",
      "Epochs 291/500 : \n",
      "Training cost 179.77015157142154| Validation cost 571257.8936724842\n",
      "Training cost 15.55074063974474| Validation cost 48936.51857155019\n",
      "Epochs 292/500 : \n",
      "Training cost 179.64922183643114| Validation cost 570870.7745030208\n",
      "Training cost 15.545008216715765| Validation cost 48918.656714904035\n",
      "Epochs 293/500 : \n",
      "Training cost 179.52887467972053| Validation cost 570485.5087394514\n",
      "Training cost 15.539298355334944| Validation cost 48900.84815562831\n",
      "Epochs 294/500 : \n",
      "Training cost 179.4091051294601| Validation cost 570102.0808722957\n",
      "Training cost 15.533610219250704| Validation cost 48883.09257858855\n",
      "Epochs 295/500 : \n",
      "Training cost 179.2899082746474| Validation cost 569720.4755781952\n",
      "Training cost 15.527938787780949| Validation cost 48865.45504062527\n",
      "Epochs 296/500 : \n",
      "Training cost 179.171279264112| Validation cost 569340.6777168838\n",
      "Training cost 15.522289258354403| Validation cost 48847.89250168137\n",
      "Epochs 297/500 : \n",
      "Training cost 179.05321330554182| Validation cost 568962.67232822\n",
      "Training cost 15.516657911180237| Validation cost 48830.409542144596\n",
      "Epochs 298/500 : \n",
      "Training cost 178.9357056645288| Validation cost 568586.4446292813\n",
      "Training cost 15.511045461379416| Validation cost 48813.05154238805\n",
      "Epochs 299/500 : \n",
      "Training cost 178.81875166363454| Validation cost 568211.9800115202\n",
      "Training cost 15.505453767317855| Validation cost 48795.78452161154\n",
      "Epochs 300/500 : \n",
      "Training cost 178.7023466814754| Validation cost 567839.2640379776\n",
      "Training cost 15.49988683338452| Validation cost 48778.61903899789\n",
      "Epochs 301/500 : \n",
      "Training cost 178.58648615182491| Validation cost 567468.2824405544\n",
      "Training cost 15.494343674203652| Validation cost 48761.50667131177\n",
      "Epochs 302/500 : \n",
      "Training cost 178.47116556273642| Validation cost 567099.0211173381\n",
      "Training cost 15.488830776848127| Validation cost 48744.466893417804\n",
      "Epochs 303/500 : \n",
      "Training cost 178.35638045568135| Validation cost 566731.4661299856\n",
      "Training cost 15.483343860558811| Validation cost 48727.47637931796\n",
      "Epochs 304/500 : \n",
      "Training cost 178.24212642470619| Validation cost 566365.6037011568\n",
      "Training cost 15.477882364789409| Validation cost 48710.56280237175\n",
      "Epochs 305/500 : \n",
      "Training cost 178.12839911560576| Validation cost 566001.4202120022\n",
      "Training cost 15.472443075600356| Validation cost 48693.72600304049\n",
      "Epochs 306/500 : \n",
      "Training cost 178.01519422511313| Validation cost 565638.9021996995\n",
      "Training cost 15.467024834595806| Validation cost 48677.01294695941\n",
      "Epochs 307/500 : \n",
      "Training cost 177.9025075001055| Validation cost 565278.0363550404\n",
      "Training cost 15.461633617110099| Validation cost 48660.35701121755\n",
      "Epochs 308/500 : \n",
      "Training cost 177.79033473682566| Validation cost 564918.8095200649\n",
      "Training cost 15.45629141510888| Validation cost 48643.771042867644\n",
      "Epochs 309/500 : \n",
      "Training cost 177.67867178011923| Validation cost 564561.2086857432\n",
      "Training cost 15.450975761871872| Validation cost 48627.29068434359\n",
      "Epochs 310/500 : \n",
      "Training cost 177.56751452268608| Validation cost 564205.2209897026\n",
      "Training cost 15.445681869549146| Validation cost 48610.93858504608\n",
      "Epochs 311/500 : \n",
      "Training cost 177.45685890434711| Validation cost 563850.8337139995\n",
      "Training cost 15.440420092331088| Validation cost 48594.633220051066\n",
      "Epochs 312/500 : \n",
      "Training cost 177.34670091132463| Validation cost 563498.0342829346\n",
      "Training cost 15.43518789138561| Validation cost 48578.40684908684\n",
      "Epochs 313/500 : \n",
      "Training cost 177.23703657553713| Validation cost 563146.8102609119\n",
      "Training cost 15.429980358079291| Validation cost 48562.231823179674\n",
      "Epochs 314/500 : \n",
      "Training cost 177.12786197390722| Validation cost 562797.1493503368\n",
      "Training cost 15.424793486378316| Validation cost 48546.163980387384\n",
      "Epochs 315/500 : \n",
      "Training cost 177.01917322768327| Validation cost 562449.0393895577\n",
      "Training cost 15.419635931161965| Validation cost 48530.190308456935\n",
      "Epochs 316/500 : \n",
      "Training cost 176.91096650177323| Validation cost 562102.4683508441\n",
      "Training cost 15.414512632355907| Validation cost 48514.261414378096\n",
      "Epochs 317/500 : \n",
      "Training cost 176.8032380040922| Validation cost 561757.424338406\n",
      "Training cost 15.409414597716156| Validation cost 48498.378310730084\n",
      "Epochs 318/500 : \n",
      "Training cost 176.69598398492136| Validation cost 561413.8955864492\n",
      "Training cost 15.404333155320417| Validation cost 48482.577680737435\n",
      "Epochs 319/500 : \n",
      "Training cost 176.58920073627948| Validation cost 561071.8704572683\n",
      "Training cost 15.399286664216946| Validation cost 48466.82005500585\n",
      "Epochs 320/500 : \n",
      "Training cost 176.48288459130598| Validation cost 560731.3374393757\n",
      "Training cost 15.394271808784053| Validation cost 48451.105196434764\n",
      "Epochs 321/500 : \n",
      "Training cost 176.3770319236557| Validation cost 560392.2851456647\n",
      "Training cost 15.38927432115937| Validation cost 48435.45118943516\n",
      "Epochs 322/500 : \n",
      "Training cost 176.2716391469048| Validation cost 560054.7023116082\n",
      "Training cost 15.38430413253435| Validation cost 48419.86237544265\n",
      "Epochs 323/500 : \n",
      "Training cost 176.16670271396774| Validation cost 559718.5777934901\n",
      "Training cost 15.379350016428722| Validation cost 48404.31546659538\n",
      "Epochs 324/500 : \n",
      "Training cost 176.0622191165248| Validation cost 559383.9005666706\n",
      "Training cost 15.374408959460167| Validation cost 48388.81023443652\n",
      "Epochs 325/500 : \n",
      "Training cost 175.95818488446045| Validation cost 559050.6597238812\n",
      "Training cost 15.369487805020762| Validation cost 48373.346452470345\n",
      "Epochs 326/500 : \n",
      "Training cost 175.85459658531164| Validation cost 558718.8444735529\n",
      "Training cost 15.364583218936225| Validation cost 48357.923896139364\n",
      "Epochs 327/500 : \n",
      "Training cost 175.75145082372651| Validation cost 558388.4441381751\n",
      "Training cost 15.359691416432685| Validation cost 48342.57231528523\n",
      "Epochs 328/500 : \n",
      "Training cost 175.6487442409324| Validation cost 558059.448152683\n",
      "Training cost 15.35481735859887| Validation cost 48327.28683821661\n",
      "Epochs 329/500 : \n",
      "Training cost 175.54647351421386| Validation cost 557731.8460628747\n",
      "Training cost 15.349958248676| Validation cost 48312.07995947113\n",
      "Epochs 330/500 : \n",
      "Training cost 175.44463535640003| Validation cost 557405.6275238574\n",
      "Training cost 15.34512914925745| Validation cost 48296.91834720909\n",
      "Epochs 331/500 : \n",
      "Training cost 175.34322651536118| Validation cost 557080.7822985216\n",
      "Training cost 15.340316963541214| Validation cost 48281.85500024527\n",
      "Epochs 332/500 : \n",
      "Training cost 175.24224377351388| Validation cost 556757.3002560403\n",
      "Training cost 15.335526600690153| Validation cost 48266.85802124793\n",
      "Epochs 333/500 : \n",
      "Training cost 175.14168394733528| Validation cost 556435.1713703986\n",
      "Training cost 15.330761099221306| Validation cost 48251.93456981944\n",
      "Epochs 334/500 : \n",
      "Training cost 175.04154388688627| Validation cost 556114.3857189461\n",
      "Training cost 15.326022762012725| Validation cost 48237.05472386507\n",
      "Epochs 335/500 : \n",
      "Training cost 174.94182047534218| Validation cost 555794.933480977\n",
      "Training cost 15.32131455595984| Validation cost 48222.213084693874\n",
      "Epochs 336/500 : \n",
      "Training cost 174.84251062853255| Validation cost 555476.8049363331\n",
      "Training cost 15.316629271720938| Validation cost 48207.447248744415\n",
      "Epochs 337/500 : \n",
      "Training cost 174.7436112944886| Validation cost 555159.9904640336\n",
      "Training cost 15.311977043723669| Validation cost 48192.73044543584\n",
      "Epochs 338/500 : \n",
      "Training cost 174.64511945299847| Validation cost 554844.4805409267\n",
      "Training cost 15.307339868824995| Validation cost 48178.05098943114\n",
      "Epochs 339/500 : \n",
      "Training cost 174.54703211517034| Validation cost 554530.2657403656\n",
      "Training cost 15.302713600306365| Validation cost 48163.40868669871\n",
      "Epochs 340/500 : \n",
      "Training cost 174.44934632300303| Validation cost 554217.3367309074\n",
      "Training cost 15.298100819272486| Validation cost 48148.81202547545\n",
      "Epochs 341/500 : \n",
      "Training cost 174.35205914896406| Validation cost 553905.6842750335\n",
      "Training cost 15.293501997027382| Validation cost 48134.265535279425\n",
      "Epochs 342/500 : \n",
      "Training cost 174.25516769557464| Validation cost 553595.2992278931\n",
      "Training cost 15.288920610538002| Validation cost 48119.75547611179\n",
      "Epochs 343/500 : \n",
      "Training cost 174.15866909500224| Validation cost 553286.1725360668\n",
      "Training cost 15.284364122132294| Validation cost 48105.28166085719\n",
      "Epochs 344/500 : \n",
      "Training cost 174.06256050865971| Validation cost 552978.2952363528\n",
      "Training cost 15.279829502256339| Validation cost 48090.84390394964\n",
      "Epochs 345/500 : \n",
      "Training cost 173.96683912681115| Validation cost 552671.6584545716\n",
      "Training cost 15.275314728304396| Validation cost 48076.45831098189\n",
      "Epochs 346/500 : \n",
      "Training cost 173.87150216818458| Validation cost 552366.2534043929\n",
      "Training cost 15.27081674400845| Validation cost 48062.132812745775\n",
      "Epochs 347/500 : \n",
      "Training cost 173.7765468795914| Validation cost 552062.0713861805\n",
      "Training cost 15.266336862021035| Validation cost 48047.842695649044\n",
      "Epochs 348/500 : \n",
      "Training cost 173.68197053555141| Validation cost 551759.1037858571\n",
      "Training cost 15.261884536064708| Validation cost 48033.58778039091\n",
      "Epochs 349/500 : \n",
      "Training cost 173.58777043792495| Validation cost 551457.3420737889\n",
      "Training cost 15.257447236892457| Validation cost 48019.39104809581\n",
      "Epochs 350/500 : \n",
      "Training cost 173.49394391555072| Validation cost 551156.7778036861\n",
      "Training cost 15.253023389324847| Validation cost 48005.260204875354\n",
      "Epochs 351/500 : \n",
      "Training cost 173.40048832388933| Validation cost 550857.402611525\n",
      "Training cost 15.248609502286442| Validation cost 47991.174035898846\n",
      "Epochs 352/500 : \n",
      "Training cost 173.30740104467358| Validation cost 550559.2082144846\n",
      "Training cost 15.244209061453523| Validation cost 47977.12693656348\n",
      "Epochs 353/500 : \n",
      "Training cost 173.21467948556338| Validation cost 550262.1864099029\n",
      "Training cost 15.239828046385314| Validation cost 47963.13543518218\n",
      "Epochs 354/500 : \n",
      "Training cost 173.12232107980734| Validation cost 549966.3290742484\n",
      "Training cost 15.235465665846753| Validation cost 47949.19596370273\n",
      "Epochs 355/500 : \n",
      "Training cost 173.030323285909| Validation cost 549671.6281621105\n",
      "Training cost 15.231120669884994| Validation cost 47935.30608719285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 356/500 : \n",
      "Training cost 172.9386835872993| Validation cost 549378.0757052029\n",
      "Training cost 15.22678869238084| Validation cost 47921.46344904531\n",
      "Epochs 357/500 : \n",
      "Training cost 172.8473994920135| Validation cost 549085.663811387\n",
      "Training cost 15.222475536385101| Validation cost 47907.65429916339\n",
      "Epochs 358/500 : \n",
      "Training cost 172.75646853237413| Validation cost 548794.3846637076\n",
      "Training cost 15.218182874928257| Validation cost 47893.87796676406\n",
      "Epochs 359/500 : \n",
      "Training cost 172.66588826467841| Validation cost 548504.2305194462\n",
      "Training cost 15.213902263504897| Validation cost 47880.15910292587\n",
      "Epochs 360/500 : \n",
      "Training cost 172.5756562688911| Validation cost 548215.1937091881\n",
      "Training cost 15.209639272076924| Validation cost 47866.48089368762\n",
      "Epochs 361/500 : \n",
      "Training cost 172.48577014834177| Validation cost 547927.266635905\n",
      "Training cost 15.205393161179297| Validation cost 47852.83484366192\n",
      "Epochs 362/500 : \n",
      "Training cost 172.39622752942753| Validation cost 547640.4417740514\n",
      "Training cost 15.201165926397117| Validation cost 47839.23132277813\n",
      "Epochs 363/500 : \n",
      "Training cost 172.30702606131976| Validation cost 547354.711668676\n",
      "Training cost 15.196952361974088| Validation cost 47825.710901619226\n",
      "Epochs 364/500 : \n",
      "Training cost 172.21816341567606| Validation cost 547070.0689345466\n",
      "Training cost 15.192756057583546| Validation cost 47812.244883133346\n",
      "Epochs 365/500 : \n",
      "Training cost 172.12963728635648| Validation cost 546786.5062552888\n",
      "Training cost 15.188582427511253| Validation cost 47798.82632648268\n",
      "Epochs 366/500 : \n",
      "Training cost 172.041445389144| Validation cost 546504.0163825375\n",
      "Training cost 15.184434989369107| Validation cost 47785.43890582574\n",
      "Epochs 367/500 : \n",
      "Training cost 171.95358546146977| Validation cost 546222.5921351031\n",
      "Training cost 15.180303398062204| Validation cost 47772.082473001064\n",
      "Epochs 368/500 : \n",
      "Training cost 171.86605526214237| Validation cost 545942.2263981479\n",
      "Training cost 15.176180816778471| Validation cost 47758.75688099447\n",
      "Epochs 369/500 : \n",
      "Training cost 171.77885257108133| Validation cost 545662.9121223788\n",
      "Training cost 15.172068966143138| Validation cost 47745.46198392651\n",
      "Epochs 370/500 : \n",
      "Training cost 171.69197518905492| Validation cost 545384.6423232486\n",
      "Training cost 15.167969843470539| Validation cost 47732.1976370401\n",
      "Epochs 371/500 : \n",
      "Training cost 171.6054209374214| Validation cost 545107.4100801726\n",
      "Training cost 15.163886435415076| Validation cost 47718.96369668842\n",
      "Epochs 372/500 : \n",
      "Training cost 171.51918765787525| Validation cost 544831.2085357546\n",
      "Training cost 15.159814824074186| Validation cost 47705.768221163045\n",
      "Epochs 373/500 : \n",
      "Training cost 171.43327321219647| Validation cost 544556.0308950274\n",
      "Training cost 15.15575693083803| Validation cost 47692.61955978351\n",
      "Epochs 374/500 : \n",
      "Training cost 171.34767548200378| Validation cost 544281.8704247018\n",
      "Training cost 15.151707565252181| Validation cost 47679.50072921421\n",
      "Epochs 375/500 : \n",
      "Training cost 171.262392368512| Validation cost 544008.7204524288\n",
      "Training cost 15.147669660589626| Validation cost 47666.43998804318\n",
      "Epochs 376/500 : \n",
      "Training cost 171.1774217922927| Validation cost 543736.5743660725\n",
      "Training cost 15.143644129230665| Validation cost 47653.41337445721\n",
      "Epochs 377/500 : \n",
      "Training cost 171.09276169303874| Validation cost 543465.4256129941\n",
      "Training cost 15.13963964689835| Validation cost 47640.41604643666\n",
      "Epochs 378/500 : \n",
      "Training cost 171.0084100293321| Validation cost 543195.2676993455\n",
      "Training cost 15.135651967917958| Validation cost 47627.48604863804\n",
      "Epochs 379/500 : \n",
      "Training cost 170.92436477841562| Validation cost 542926.0941893748\n",
      "Training cost 15.131673067745426| Validation cost 47614.6183639543\n",
      "Epochs 380/500 : \n",
      "Training cost 170.84062393596736| Validation cost 542657.898704741\n",
      "Training cost 15.127708937743934| Validation cost 47601.77973988033\n",
      "Epochs 381/500 : \n",
      "Training cost 170.75718551587937| Validation cost 542390.6749238396\n",
      "Training cost 15.123760046041989| Validation cost 47589.02964870712\n",
      "Epochs 382/500 : \n",
      "Training cost 170.67404755003892| Validation cost 542124.4165811376\n",
      "Training cost 15.119826789383447| Validation cost 47576.347400148836\n",
      "Epochs 383/500 : \n",
      "Training cost 170.59120808811332| Validation cost 541859.1174665182\n",
      "Training cost 15.115908391757975| Validation cost 47563.70626309955\n",
      "Epochs 384/500 : \n",
      "Training cost 170.50866519733805| Validation cost 541594.7714246357\n",
      "Training cost 15.112004121596405| Validation cost 47551.09273199254\n",
      "Epochs 385/500 : \n",
      "Training cost 170.4264169623075| Validation cost 541331.3723542787\n",
      "Training cost 15.108121539083337| Validation cost 47538.52767356259\n",
      "Epochs 386/500 : \n",
      "Training cost 170.34446148476954| Validation cost 541068.914207744\n",
      "Training cost 15.104252759473583| Validation cost 47526.075609761145\n",
      "Epochs 387/500 : \n",
      "Training cost 170.26279688342228| Validation cost 540807.3909902185\n",
      "Training cost 15.100395138180907| Validation cost 47513.67476370391\n",
      "Epochs 388/500 : \n",
      "Training cost 170.1814212937145| Validation cost 540546.7967591699\n",
      "Training cost 15.096547573974634| Validation cost 47501.420795211\n",
      "Epochs 389/500 : \n",
      "Training cost 170.10033286764863| Validation cost 540287.1256237471\n",
      "Training cost 15.09271693645055| Validation cost 47489.21963296726\n",
      "Epochs 390/500 : \n",
      "Training cost 170.0195297735866| Validation cost 540028.3717441881\n",
      "Training cost 15.088896060459946| Validation cost 47477.06715118165\n",
      "Epochs 391/500 : \n",
      "Training cost 169.9390101960585| Validation cost 539770.5293312374\n",
      "Training cost 15.085085637555936| Validation cost 47464.98937963565\n",
      "Epochs 392/500 : \n",
      "Training cost 169.85877233557426| Validation cost 539513.592645571\n",
      "Training cost 15.081287301584352| Validation cost 47452.937487413416\n",
      "Epochs 393/500 : \n",
      "Training cost 169.77881440843757| Validation cost 539257.5559972294\n",
      "Training cost 15.07750458984461| Validation cost 47440.94206088052\n",
      "Epochs 394/500 : \n",
      "Training cost 169.69913464656307| Validation cost 539002.4137450595\n",
      "Training cost 15.073736174686616| Validation cost 47428.978554890986\n",
      "Epochs 395/500 : \n",
      "Training cost 169.61973129729554| Validation cost 538748.1602961638\n",
      "Training cost 15.06997993342909| Validation cost 47417.04020731393\n",
      "Epochs 396/500 : \n",
      "Training cost 169.54060262323213| Validation cost 538494.7901053566\n",
      "Training cost 15.066236659378935| Validation cost 47405.126907680096\n",
      "Epochs 397/500 : \n",
      "Training cost 169.4617469020469| Validation cost 538242.2976746303\n",
      "Training cost 15.062502371937885| Validation cost 47393.266230129186\n",
      "Epochs 398/500 : \n",
      "Training cost 169.3831624263178| Validation cost 537990.6775526255\n",
      "Training cost 15.058781920837951| Validation cost 47381.491710804825\n",
      "Epochs 399/500 : \n",
      "Training cost 169.30484750335654| Validation cost 537739.9243341122\n",
      "Training cost 15.055079592682832| Validation cost 47369.741786968734\n",
      "Epochs 400/500 : \n",
      "Training cost 169.22680045504006| Validation cost 537490.032659475\n",
      "Training cost 15.051394739536905| Validation cost 47358.016350559155\n",
      "Epochs 401/500 : \n",
      "Training cost 169.1490196176452| Validation cost 537240.9972142081\n",
      "Training cost 15.04772104251689| Validation cost 47346.32389009102\n",
      "Epochs 402/500 : \n",
      "Training cost 169.07150334168531| Validation cost 536992.8127284157\n",
      "Training cost 15.044058744451045| Validation cost 47334.67373010314\n",
      "Epochs 403/500 : \n",
      "Training cost 168.99424999174886| Validation cost 536745.4739763195\n",
      "Training cost 15.040407912904975| Validation cost 47323.04759372806\n",
      "Epochs 404/500 : \n",
      "Training cost 168.91725794634107| Validation cost 536498.9757757733\n",
      "Training cost 15.036766986900975| Validation cost 47311.44537691212\n",
      "Epochs 405/500 : \n",
      "Training cost 168.84052559772678| Validation cost 536253.3129877842\n",
      "Training cost 15.033137332336583| Validation cost 47299.866976349345\n",
      "Epochs 406/500 : \n",
      "Training cost 168.76405135177654| Validation cost 536008.4805160398\n",
      "Training cost 15.029516914347216| Validation cost 47288.31228947357\n",
      "Epochs 407/500 : \n",
      "Training cost 168.68783362781397| Validation cost 535764.4733064432\n",
      "Training cost 15.025907865633675| Validation cost 47276.79689072563\n",
      "Epochs 408/500 : \n",
      "Training cost 168.61187085846555| Validation cost 535521.2863466528\n",
      "Training cost 15.02231154216145| Validation cost 47265.311632102486\n",
      "Epochs 409/500 : \n",
      "Training cost 168.53616148951278| Validation cost 535278.9146656286\n",
      "Training cost 15.018727679792946| Validation cost 47253.91146136864\n",
      "Epochs 410/500 : \n",
      "Training cost 168.4607039797459| Validation cost 535037.3533331855\n",
      "Training cost 15.015160551589156| Validation cost 47242.55448062929\n",
      "Epochs 411/500 : \n",
      "Training cost 168.38549680081968| Validation cost 534796.5974595523\n",
      "Training cost 15.011607326520458| Validation cost 47231.23027564074\n",
      "Epochs 412/500 : \n",
      "Training cost 168.31053843711157| Validation cost 534556.6421949359\n",
      "Training cost 15.008070546434382| Validation cost 47219.963556801435\n",
      "Epochs 413/500 : \n",
      "Training cost 168.23582738558144| Validation cost 534317.4827290919\n",
      "Training cost 15.00455233739608| Validation cost 47208.72925817541\n",
      "Epochs 414/500 : \n",
      "Training cost 168.16136215563324| Validation cost 534079.1142909012\n",
      "Training cost 15.001046504332102| Validation cost 47197.517289559284\n",
      "Epochs 415/500 : \n",
      "Training cost 168.08714126897874| Validation cost 533841.5321479518\n",
      "Training cost 14.997549838614205| Validation cost 47186.3275579187\n",
      "Epochs 416/500 : \n",
      "Training cost 168.01316325950285| Validation cost 533604.7316061262\n",
      "Training cost 14.994067453043897| Validation cost 47175.159970864406\n",
      "Epochs 417/500 : \n",
      "Training cost 167.93942667313107| Validation cost 533368.7080091945\n",
      "Training cost 14.990598194568017| Validation cost 47164.024172855316\n",
      "Epochs 418/500 : \n",
      "Training cost 167.86593006769837| Validation cost 533133.4567384128\n",
      "Training cost 14.987138584639597| Validation cost 47152.923824468606\n",
      "Epochs 419/500 : \n",
      "Training cost 167.79267201282022| Validation cost 532898.9732121266\n",
      "Training cost 14.983696763432354| Validation cost 47141.845293717575\n",
      "Epochs 420/500 : \n",
      "Training cost 167.71965108976488| Validation cost 532665.2528853802\n",
      "Training cost 14.980264399538164| Validation cost 47130.78849091195\n",
      "Epochs 421/500 : \n",
      "Training cost 167.64686589132813| Validation cost 532432.2912495298\n",
      "Training cost 14.976842584577208| Validation cost 47119.79258336959\n",
      "Epochs 422/500 : \n",
      "Training cost 167.57431502170857| Validation cost 532200.0838318636\n",
      "Training cost 14.973432188927655| Validation cost 47108.83312688294\n",
      "Epochs 423/500 : \n",
      "Training cost 167.50199709638596| Validation cost 531968.6261952248\n",
      "Training cost 14.970033727840168| Validation cost 47097.906387605966\n",
      "Epochs 424/500 : \n",
      "Training cost 167.42991074199972| Validation cost 531737.9139376414\n",
      "Training cost 14.966644391444495| Validation cost 47087.05047241945\n",
      "Epochs 425/500 : \n",
      "Training cost 167.35805459623035| Validation cost 531507.9426919597\n",
      "Training cost 14.96326539027071| Validation cost 47076.29716697074\n",
      "Epochs 426/500 : \n",
      "Training cost 167.28642730768144| Validation cost 531278.7081254821\n",
      "Training cost 14.959912892152355| Validation cost 47065.568470902974\n",
      "Epochs 427/500 : \n",
      "Training cost 167.21502753576377| Validation cost 531050.2059396113\n",
      "Training cost 14.956571255150196| Validation cost 47054.87882967423\n",
      "Epochs 428/500 : \n",
      "Training cost 167.14385395058085| Validation cost 530822.4318694973\n",
      "Training cost 14.953239863071165| Validation cost 47044.24833237989\n",
      "Epochs 429/500 : \n",
      "Training cost 167.07290523281577| Validation cost 530595.3816836902\n",
      "Training cost 14.949925877803942| Validation cost 47033.63818995637\n",
      "Epochs 430/500 : \n",
      "Training cost 167.00218007361983| Validation cost 530369.0511837965\n",
      "Training cost 14.946629290952584| Validation cost 47023.05516773915\n",
      "Epochs 431/500 : \n",
      "Training cost 166.93167717450225| Validation cost 530143.4362041404\n",
      "Training cost 14.943339872441303| Validation cost 47012.51118704132\n",
      "Epochs 432/500 : \n",
      "Training cost 166.8613952472217| Validation cost 529918.5326114295\n",
      "Training cost 14.940056496215504| Validation cost 47002.02122048913\n",
      "Epochs 433/500 : \n",
      "Training cost 166.7913330136791| Validation cost 529694.3363044242\n",
      "Training cost 14.936778935935019| Validation cost 46991.55108830512\n",
      "Epochs 434/500 : \n",
      "Training cost 166.72148920581154| Validation cost 529470.8432136119\n",
      "Training cost 14.933510329320086| Validation cost 46981.100710468185\n",
      "Epochs 435/500 : \n",
      "Training cost 166.65186256548807| Validation cost 529248.0493008847\n",
      "Training cost 14.930251515973042| Validation cost 46970.67000749166\n",
      "Epochs 436/500 : \n",
      "Training cost 166.58245184440653| Validation cost 529025.950559222\n",
      "Training cost 14.927004690258853| Validation cost 46960.258900418085\n",
      "Epochs 437/500 : \n",
      "Training cost 166.51325580399168| Validation cost 528804.5430123762\n",
      "Training cost 14.923776237045804| Validation cost 46949.86731081399\n",
      "Epochs 438/500 : \n",
      "Training cost 166.4442732152947| Validation cost 528583.8227145632\n",
      "Training cost 14.920565941050533| Validation cost 46939.495160764855\n",
      "Epochs 439/500 : \n",
      "Training cost 166.3755028588942| Validation cost 528363.7857501556\n",
      "Training cost 14.917368815494706| Validation cost 46929.14237286998\n",
      "Epochs 440/500 : \n",
      "Training cost 166.30694352479813| Validation cost 528144.4282333816\n",
      "Training cost 14.914177573677105| Validation cost 46918.83948748346\n",
      "Epochs 441/500 : \n",
      "Training cost 166.23859401234716| Validation cost 527925.7463080259\n",
      "Training cost 14.910993327169622| Validation cost 46908.57215809546\n",
      "Epochs 442/500 : \n",
      "Training cost 166.17045313011923| Validation cost 527707.7361471353\n",
      "Training cost 14.907820200719557| Validation cost 46898.32514698698\n",
      "Epochs 443/500 : \n",
      "Training cost 166.10251969583547| Validation cost 527490.393952727\n",
      "Training cost 14.904662253110097| Validation cost 46888.097123757274\n",
      "Epochs 444/500 : \n",
      "Training cost 166.0347925362669| Validation cost 527273.7159555021\n",
      "Training cost 14.901511782354092| Validation cost 46877.89249345378\n",
      "Epochs 445/500 : \n",
      "Training cost 165.96727048714288| Validation cost 527057.6984145615\n",
      "Training cost 14.89836747022786| Validation cost 46867.71703981403\n",
      "Epochs 446/500 : \n",
      "Training cost 165.8999523930603| Validation cost 526842.3376171249\n",
      "Training cost 14.895232579864745| Validation cost 46857.56032379195\n",
      "Epochs 447/500 : \n",
      "Training cost 165.83283710739394| Validation cost 526627.6298782548\n",
      "Training cost 14.892102992250557| Validation cost 46847.44273011205\n",
      "Epochs 448/500 : \n",
      "Training cost 165.76592349220832| Validation cost 526413.5715405826\n",
      "Training cost 14.888980537185597| Validation cost 46837.34877460072\n",
      "Epochs 449/500 : \n",
      "Training cost 165.6992104181701| Validation cost 526200.1589740382\n",
      "Training cost 14.885867453953702| Validation cost 46827.273283476636\n",
      "Epochs 450/500 : \n",
      "Training cost 165.63269676446222| Validation cost 525987.3885755837\n",
      "Training cost 14.882769255992434| Validation cost 46817.216184602\n",
      "Epochs 451/500 : \n",
      "Training cost 165.56638141869834| Validation cost 525775.2567689493\n",
      "Training cost 14.87968131629494| Validation cost 46807.179444560745\n",
      "Epochs 452/500 : \n",
      "Training cost 165.50026327683923| Validation cost 525563.7600043738\n",
      "Training cost 14.876604575780934| Validation cost 46797.16648007059\n",
      "Epochs 453/500 : \n",
      "Training cost 165.43434124310934| Validation cost 525352.8947583463\n",
      "Training cost 14.873538004487534| Validation cost 46787.17165507715\n",
      "Epochs 454/500 : \n",
      "Training cost 165.3686142299152| Validation cost 525142.6575333523\n",
      "Training cost 14.870482032128523| Validation cost 46777.19489951705\n",
      "Epochs 455/500 : \n",
      "Training cost 165.3030811577641| Validation cost 524933.044857624\n",
      "Training cost 14.867433805990148| Validation cost 46767.24783734874\n",
      "Epochs 456/500 : \n",
      "Training cost 165.23774095518436| Validation cost 524724.053284891\n",
      "Training cost 14.864391559759513| Validation cost 46757.32508596845\n",
      "Epochs 457/500 : \n",
      "Training cost 165.1725925586463| Validation cost 524515.6793941354\n",
      "Training cost 14.861358825602307| Validation cost 46747.424394279355\n",
      "Epochs 458/500 : \n",
      "Training cost 165.1076349124842| Validation cost 524307.9197893505\n",
      "Training cost 14.858334685217503| Validation cost 46737.543470096214\n",
      "Epochs 459/500 : \n",
      "Training cost 165.04286696881914| Validation cost 524100.77109930106\n",
      "Training cost 14.85532461706503| Validation cost 46727.680735598755\n",
      "Epochs 460/500 : \n",
      "Training cost 164.9782876874832| Validation cost 523894.2299772875\n",
      "Training cost 14.85232079000834| Validation cost 46717.87672584754\n",
      "Epochs 461/500 : \n",
      "Training cost 164.91389603594402| Validation cost 523688.2931009119\n",
      "Training cost 14.849323135515586| Validation cost 46708.0903686485\n",
      "Epochs 462/500 : \n",
      "Training cost 164.84969098923068| Validation cost 523482.95717184775\n",
      "Training cost 14.84633300854951| Validation cost 46698.32123463658\n",
      "Epochs 463/500 : \n",
      "Training cost 164.78567152986025| Validation cost 523278.218915612\n",
      "Training cost 14.843351170538583| Validation cost 46688.56925917852\n",
      "Epochs 464/500 : \n",
      "Training cost 164.72183664776549| Validation cost 523074.0750813399\n",
      "Training cost 14.840378315711309| Validation cost 46678.83437803895\n",
      "Epochs 465/500 : \n",
      "Training cost 164.6581853402231| Validation cost 522870.5224415619\n",
      "Training cost 14.837412423159568| Validation cost 46669.13594822159\n",
      "Epochs 466/500 : \n",
      "Training cost 164.59471661178313| Validation cost 522667.55779198493\n",
      "Training cost 14.834451274875493| Validation cost 46659.46340673307\n",
      "Epochs 467/500 : \n",
      "Training cost 164.5314294741993| Validation cost 522465.17795127386\n",
      "Training cost 14.83149849551914| Validation cost 46649.83793563629\n",
      "Epochs 468/500 : \n",
      "Training cost 164.4683229463595| Validation cost 522263.37976083724\n",
      "Training cost 14.828561034575747| Validation cost 46640.23698165803\n",
      "Epochs 469/500 : \n",
      "Training cost 164.4053960542181| Validation cost 522062.1600846152\n",
      "Training cost 14.825629450280385| Validation cost 46630.65468314737\n",
      "Epochs 470/500 : \n",
      "Training cost 164.3426478307284| Validation cost 521861.5158088694\n",
      "Training cost 14.8227025155201| Validation cost 46621.08881332288\n",
      "Epochs 471/500 : \n",
      "Training cost 164.28007731577603| Validation cost 521661.44384197623\n",
      "Training cost 14.81978021476938| Validation cost 46611.53931207975\n",
      "Epochs 472/500 : \n",
      "Training cost 164.21768355611331| Validation cost 521461.94111422135\n",
      "Training cost 14.81686718671921| Validation cost 46602.00611967449\n",
      "Epochs 473/500 : \n",
      "Training cost 164.1554656052943| Validation cost 521263.00457759737\n",
      "Training cost 14.813961554200116| Validation cost 46592.489176721676\n",
      "Epochs 474/500 : \n",
      "Training cost 164.09342252361043| Validation cost 521064.63120560406\n",
      "Training cost 14.811070088756765| Validation cost 46582.988424190815\n",
      "Epochs 475/500 : \n",
      "Training cost 164.03155337802727| Validation cost 520866.8179930501\n",
      "Training cost 14.80818445644314| Validation cost 46573.5038034031\n",
      "Epochs 476/500 : \n",
      "Training cost 163.96985724212175| Validation cost 520669.56195585773\n",
      "Training cost 14.80530406295812| Validation cost 46564.03525602832\n",
      "Epochs 477/500 : \n",
      "Training cost 163.9083331960203| Validation cost 520472.86013086955\n",
      "Training cost 14.802430490613952| Validation cost 46554.582724081716\n",
      "Epochs 478/500 : \n",
      "Training cost 163.84698032633756| Validation cost 520276.7095756572\n",
      "Training cost 14.79956299520496| Validation cost 46545.16266047889\n",
      "Epochs 479/500 : \n",
      "Training cost 163.785797726116| Validation cost 520081.10736833286\n",
      "Training cost 14.796699954273853| Validation cost 46535.81350734865\n",
      "Epochs 480/500 : \n",
      "Training cost 163.7247844947661| Validation cost 519886.0506073624\n",
      "Training cost 14.793847711689242| Validation cost 46526.51926587426\n",
      "Epochs 481/500 : \n",
      "Training cost 163.6639397380073| Validation cost 519691.53641138086\n",
      "Training cost 14.791003654179136| Validation cost 46517.24291280376\n",
      "Epochs 482/500 : \n",
      "Training cost 163.60326256780962| Validation cost 519497.56191901007\n",
      "Training cost 14.788163982330154| Validation cost 46507.99560579033\n",
      "Epochs 483/500 : \n",
      "Training cost 163.54275210233598| Validation cost 519304.12428867794\n",
      "Training cost 14.78532868186265| Validation cost 46498.77864447258\n",
      "Epochs 484/500 : \n",
      "Training cost 163.48240746588525| Validation cost 519111.2206984408\n",
      "Training cost 14.782498579970003| Validation cost 46489.57690652787\n",
      "Epochs 485/500 : \n",
      "Training cost 163.42222778883584| Validation cost 518918.8483458066\n",
      "Training cost 14.779677710646366| Validation cost 46480.390337899866\n",
      "Epochs 486/500 : \n",
      "Training cost 163.36221220758998| Validation cost 518727.0044475607\n",
      "Training cost 14.776864911231716| Validation cost 46471.218884847156\n",
      "Epochs 487/500 : \n",
      "Training cost 163.30235986451876| Validation cost 518535.6862395939\n",
      "Training cost 14.77406079475206| Validation cost 46462.062493940495\n",
      "Epochs 488/500 : \n",
      "Training cost 163.24266990790767| Validation cost 518344.8909767317\n",
      "Training cost 14.771261186236128| Validation cost 46452.92111206006\n",
      "Epochs 489/500 : \n",
      "Training cost 163.18314149190283| Validation cost 518154.615932566\n",
      "Training cost 14.768466044413104| Validation cost 46443.79468639276\n",
      "Epochs 490/500 : \n",
      "Training cost 163.12377377645785| Validation cost 517964.85839928855\n",
      "Training cost 14.765687585246134| Validation cost 46434.683164429596\n",
      "Epochs 491/500 : \n",
      "Training cost 163.06456592728128| Validation cost 517775.6156875262\n",
      "Training cost 14.762920794869247| Validation cost 46425.587812892074\n",
      "Epochs 492/500 : \n",
      "Training cost 163.00551711578467| Validation cost 517586.88512617804\n",
      "Training cost 14.760163248617204| Validation cost 46416.53363090704\n",
      "Epochs 493/500 : \n",
      "Training cost 162.9466265190312| Validation cost 517398.6640622547\n",
      "Training cost 14.757417180639232| Validation cost 46407.49921064553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 494/500 : \n",
      "Training cost 162.887893319685| Validation cost 517210.94986071857\n",
      "Training cost 14.754681506300349| Validation cost 46398.50743632937\n",
      "Epochs 495/500 : \n",
      "Training cost 162.82931670596088| Validation cost 517023.73990432674\n",
      "Training cost 14.751954027106803| Validation cost 46389.55387689236\n",
      "Epochs 496/500 : \n",
      "Training cost 162.77089587157477| Validation cost 516837.0315934752\n",
      "Training cost 14.74923785263186| Validation cost 46380.63753475758\n",
      "Epochs 497/500 : \n",
      "Training cost 162.71263001569469| Validation cost 516650.8223460447\n",
      "Training cost 14.74652991125608| Validation cost 46371.79015428276\n",
      "Epochs 498/500 : \n",
      "Training cost 162.6545183428923| Validation cost 516465.10959724884\n",
      "Training cost 14.743828969955164| Validation cost 46362.97363937566\n",
      "Epochs 499/500 : \n",
      "Training cost 162.59656006309478| Validation cost 516279.8907994828\n",
      "Training cost 14.741131982438471| Validation cost 46354.171110258125\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "linear_regression_model(X_train,y_train,X_val,y_val,0.4,500) \n",
    "# feeding data to our LR model with learning rate 0.4 upto 500 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#error at 1st iteration was 2026 whcich is reduced to 162 after 500 iterations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
